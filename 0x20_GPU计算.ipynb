{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0x20_GPU计算.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPP9jhOX+Qx+FCr2oGtqzpQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrixmax/Dive_into_DeepLearning/blob/main/0x20_GPU%E8%AE%A1%E7%AE%97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUviPeZ-yW2L"
      },
      "source": [
        "到目前为止，我们一直在使用CPU计算。对复杂的神经网络和大规模的数据来说，使用CPU来计算可能不够高效。在本节中，我们将介绍如何使用单块NVIDIA GPU来计算。所以需要确保已经安装好了PyTorch GPU版本。准备工作都完成后，下面就可以通过nvidia-smi命令来查看显卡信息了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6VcM3HyRTM",
        "outputId": "ae53b824-2f53-45e5-fab4-9bf645f48fad"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 14 09:06:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmOUKaOXy4Cs"
      },
      "source": [
        "## 1. 计算设备\r\n",
        "PyTorch可以指定用来存储和计算的设备，如使用内存的CPU或者使用显存的GPU。默认情况下，PyTorch会将数据创建在内存，然后利用CPU来计算。\r\n",
        "\r\n",
        "使用 torch.cuda.is_available() 查看GPU是否可用\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIwiTboLzEt9",
        "outputId": "981dc6da-a1bf-43f9-8c58-9fff5b81ce98"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "torch.cuda.is_available()\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkiGERa4zMpW",
        "outputId": "8f150bd3-3308-40c4-9018-a0f08b16fb49"
      },
      "source": [
        "# 查看GPU数量\r\n",
        "torch.cuda.device_count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zPl2jM1zSP4",
        "outputId": "2f1742a7-fdbf-4697-ca64-1395b9c91917"
      },
      "source": [
        "# 查看当前GPU索引号，索引从0开始\r\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eCFl70oaza8k",
        "outputId": "5a25b560-c4ea-4a37-aa78-dcd83ed37876"
      },
      "source": [
        "# 根据索引号查看GPU名字\r\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QCnZBY6zjtm"
      },
      "source": [
        "## 2.Tensor的GPU计算\r\n",
        "默认情况下，Tensor会被存在内存上，因此，之前我们每次打印tensor的时候看不到GPU相关标识"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4febYJc5zjQf",
        "outputId": "c581aa39-14d9-4023-ecb0-eb1d911dcaa9"
      },
      "source": [
        "x = torch.tensor([1,2,3])\r\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iOKTwsa0PGD"
      },
      "source": [
        "使用.cuda()可以将CPU上的Tensor转换（复制）到GPU上，如果有多块GPU，我们用.cuda(i)来表示第$i$块GPU以及相关的显存（$i$从0开始）且cuda(0)和cuda()等价"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWiagrdu0OwC",
        "outputId": "7417e1e0-979e-40ec-d7d2-0abfdb12c2da"
      },
      "source": [
        "x = x.cuda(0)\r\n",
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWY6oUrq0Y_2",
        "outputId": "afababc9-ac65-4e27-d9b5-b88c2e42e145"
      },
      "source": [
        "# 我们可以通过Tensor的device属性来查看该Tensor所在的设备。\r\n",
        "x.device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J3R2JXQz1rN",
        "outputId": "86587bac-97bb-4e37-c3be-7bc66a04e0d4"
      },
      "source": [
        "# 我们可以直接在创建的时候就指定设备。\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "x = torch.tensor([1,2,3],device = device)\r\n",
        "\r\n",
        "# or\r\n",
        "# x = torch.tensor([1,2,3]).to(device)\r\n",
        "x"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXiiDdmt0zWu",
        "outputId": "27027f45-b802-4dc0-ff92-bffb73298cfc"
      },
      "source": [
        "# 如果对在GPU上的数据进行运算，那么结果还是存放在GPU上。\r\n",
        "y  = x**2\r\n",
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgbGz5kb0XXO"
      },
      "source": [
        "**需要注意的是，存储在不同位置中的数据是不可以直接进行计算的。即存放在CPU上的数据不可以直接与存放在GPU上的数据进行运算，位于不同GPU上的数据也是不能直接进行计算的。**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "5glrtSEN05-c",
        "outputId": "150e0439-54c4-4515-e474-65ceb0e3f8db"
      },
      "source": [
        "z = y+x.cpu()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-68e2777ca07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0oqGdj1Ddl"
      },
      "source": [
        "## 3.模型的GPU计算\r\n",
        "同Tensor类似，PyTorch模型也可以通过.cuda转换到GPU上。我们可以通过检查模型的参数的device属性来查看存放模型的设备。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89_yISRO1Iub",
        "outputId": "f2765451-a9f5-4327-da22-6d9a6d48a582"
      },
      "source": [
        "net = nn.Linear(3,1)\r\n",
        "list(net.parameters())[0].device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amoVBXlj1Q6f",
        "outputId": "1563a81f-568c-4e83-c4a2-fbaa3e43fa3b"
      },
      "source": [
        "# 可见模型在CPU上，将其转换到GPU上:\r\n",
        "net.cuda()\r\n",
        "list(net.parameters())[0].device"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ibkEfSw1ZxX"
      },
      "source": [
        "**同样的，我么需要保证模型输入的Tensor和模型都在同一设备上，否则会报错。**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jj1IvD61bFi",
        "outputId": "c930903f-2898-4c1d-8c8f-6ffaae5bbd94"
      },
      "source": [
        "x = torch.rand(2,3).cuda()\r\n",
        "net(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4562],\n",
              "        [0.6498]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC71DK2o1Qfj"
      },
      "source": [
        ""
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0x12_丢弃法.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMupMmm562vc0cKK9cPdkMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrixmax/Dive_into_DeepLearning/blob/main/0x12_%E4%B8%A2%E5%BC%83%E6%B3%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tnbLDyUjVWT"
      },
      "source": [
        "## 1. 方法\r\n",
        "\r\n",
        "除了前一节介绍的权重衰减以外，深度学习模型常常使用丢弃法（dropout）[1] 来应对过拟合问题。丢弃法有一些不同的变体。本节中提到的丢弃法特指倒置丢弃法（inverted dropout）。\r\n",
        "\r\n",
        "当对该隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。设丢弃概率为p，那么有pp的概率hi​会被清零，有1−p的概率hi会除以1−p做拉伸。丢弃概率是丢弃法的超参数。\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl6L6oMrk1Ag"
      },
      "source": [
        "## 2. 从零开始实现\r\n",
        "下面的dropout函数将以drop_prob的概率丢弃X中的元素。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6LSpD6oUWhD"
      },
      "source": [
        " \r\n",
        "# This file is generated automatically through:\r\n",
        "#    d2lbook build lib\r\n",
        "# Don't edit it directly\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preface/index.md\r\n",
        "import collections\r\n",
        "import hashlib\r\n",
        "import math\r\n",
        "import os\r\n",
        "import random\r\n",
        "import re\r\n",
        "import shutil\r\n",
        "import sys\r\n",
        "import tarfile\r\n",
        "import time\r\n",
        "import zipfile\r\n",
        "from collections import defaultdict\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import requests\r\n",
        "from IPython import display\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "d2l = sys.modules[__name__]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preface/index.md\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torch import nn\r\n",
        "from torch.nn import functional as F\r\n",
        "from torch.utils import data\r\n",
        "from torchvision import transforms\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preliminaries/calculus.md\r\n",
        "def use_svg_display():\r\n",
        "    \"\"\"使用svg格式在Jupyter中显示绘图。\"\"\"\r\n",
        "    display.set_matplotlib_formats('svg')\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preliminaries/calculus.md\r\n",
        "def set_figsize(figsize=(3.5, 2.5)):\r\n",
        "    \"\"\"设置matplotlib的图表大小。\"\"\"\r\n",
        "    use_svg_display()\r\n",
        "    d2l.plt.rcParams['figure.figsize'] = figsize\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preliminaries/calculus.md\r\n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\r\n",
        "    \"\"\"设置matplotlib的轴。\"\"\"\r\n",
        "    axes.set_xlabel(xlabel)\r\n",
        "    axes.set_ylabel(ylabel)\r\n",
        "    axes.set_xscale(xscale)\r\n",
        "    axes.set_yscale(yscale)\r\n",
        "    axes.set_xlim(xlim)\r\n",
        "    axes.set_ylim(ylim)\r\n",
        "    if legend:\r\n",
        "        axes.legend(legend)\r\n",
        "    axes.grid()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_preliminaries/calculus.md\r\n",
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\r\n",
        "         ylim=None, xscale='linear', yscale='linear',\r\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\r\n",
        "    \"\"\"绘制数据点。\"\"\"\r\n",
        "    if legend is None:\r\n",
        "        legend = []\r\n",
        "\r\n",
        "    set_figsize(figsize)\r\n",
        "    axes = axes if axes else d2l.plt.gca()\r\n",
        "\r\n",
        "    # Return True if `X` (tensor or list) has 1 axis\r\n",
        "    def has_one_axis(X):\r\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or\r\n",
        "                isinstance(X, list) and not hasattr(X[0], \"__len__\"))\r\n",
        "\r\n",
        "    if has_one_axis(X):\r\n",
        "        X = [X]\r\n",
        "    if Y is None:\r\n",
        "        X, Y = [[]] * len(X), X\r\n",
        "    elif has_one_axis(Y):\r\n",
        "        Y = [Y]\r\n",
        "    if len(X) != len(Y):\r\n",
        "        X = X * len(Y)\r\n",
        "    axes.cla()\r\n",
        "    for x, y, fmt in zip(X, Y, fmts):\r\n",
        "        if len(x):\r\n",
        "            axes.plot(x, y, fmt)\r\n",
        "        else:\r\n",
        "            axes.plot(y, fmt)\r\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression.md\r\n",
        "class Timer:\r\n",
        "    \"\"\"记录多次运行时间。\"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        self.times = []\r\n",
        "        self.start()\r\n",
        "\r\n",
        "    def start(self):\r\n",
        "        \"\"\"启动计时器。\"\"\"\r\n",
        "        self.tik = time.time()\r\n",
        "\r\n",
        "    def stop(self):\r\n",
        "        \"\"\"停止计时器并将时间记录在列表中。\"\"\"\r\n",
        "        self.times.append(time.time() - self.tik)\r\n",
        "        return self.times[-1]\r\n",
        "\r\n",
        "    def avg(self):\r\n",
        "        \"\"\"返回平均时间。\"\"\"\r\n",
        "        return sum(self.times) / len(self.times)\r\n",
        "\r\n",
        "    def sum(self):\r\n",
        "        \"\"\"返回时间总和。\"\"\"\r\n",
        "        return sum(self.times)\r\n",
        "\r\n",
        "    def cumsum(self):\r\n",
        "        \"\"\"返回累计时间。\"\"\"\r\n",
        "        return np.array(self.times).cumsum().tolist()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression-scratch.md\r\n",
        "def synthetic_data(w, b, num_examples):\r\n",
        "    \"\"\"生成 y = Xw + b + 噪声。\"\"\"\r\n",
        "    X = d2l.normal(0, 1, (num_examples, len(w)))\r\n",
        "    y = d2l.matmul(X, w) + b\r\n",
        "    y += d2l.normal(0, 0.01, y.shape)\r\n",
        "    return X, d2l.reshape(y, (-1, 1))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression-scratch.md\r\n",
        "def linreg(X, w, b):\r\n",
        "    \"\"\"线性回归模型。\"\"\"\r\n",
        "    return d2l.matmul(X, w) + b\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression-scratch.md\r\n",
        "def squared_loss(y_hat, y):\r\n",
        "    \"\"\"均方损失。\"\"\"\r\n",
        "    return (y_hat - d2l.reshape(y, y_hat.shape))**2 / 2\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression-scratch.md\r\n",
        "def sgd(params, lr, batch_size):\r\n",
        "    \"\"\"小批量随机梯度下降。\"\"\"\r\n",
        "    with torch.no_grad():\r\n",
        "        for param in params:\r\n",
        "            param -= lr * param.grad / batch_size\r\n",
        "            param.grad.zero_()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/linear-regression-concise.md\r\n",
        "def load_array(data_arrays, batch_size, is_train=True):\r\n",
        "    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\r\n",
        "    dataset = data.TensorDataset(*data_arrays)\r\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/image-classification-dataset.md\r\n",
        "def get_fashion_mnist_labels(labels):\r\n",
        "    \"\"\"返回Fashion-MNIST数据集的文本标签。\"\"\"\r\n",
        "    text_labels = [\r\n",
        "        't-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt',\r\n",
        "        'sneaker', 'bag', 'ankle boot']\r\n",
        "    return [text_labels[int(i)] for i in labels]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/image-classification-dataset.md\r\n",
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\r\n",
        "    \"\"\"Plot a list of images.\"\"\"\r\n",
        "    figsize = (num_cols * scale, num_rows * scale)\r\n",
        "    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\r\n",
        "    axes = axes.flatten()\r\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\r\n",
        "        if torch.is_tensor(img):\r\n",
        "            # 图片张量\r\n",
        "            ax.imshow(img.numpy())\r\n",
        "        else:\r\n",
        "            # PIL图片\r\n",
        "            ax.imshow(img)\r\n",
        "        ax.axes.get_xaxis().set_visible(False)\r\n",
        "        ax.axes.get_yaxis().set_visible(False)\r\n",
        "        if titles:\r\n",
        "            ax.set_title(titles[i])\r\n",
        "    return axes\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/image-classification-dataset.md\r\n",
        "def get_dataloader_workers():\r\n",
        "    \"\"\"使用4个进程来读取的数据。\"\"\"\r\n",
        "    return 4\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/image-classification-dataset.md\r\n",
        "def load_data_fashion_mnist(batch_size, resize=None):\r\n",
        "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中。\"\"\"\r\n",
        "    trans = [transforms.ToTensor()]\r\n",
        "    if resize:\r\n",
        "        trans.insert(0, transforms.Resize(resize))\r\n",
        "    trans = transforms.Compose(trans)\r\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\",\r\n",
        "                                                    train=True,\r\n",
        "                                                    transform=trans,\r\n",
        "                                                    download=True)\r\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",\r\n",
        "                                                   train=False,\r\n",
        "                                                   transform=trans,\r\n",
        "                                                   download=True)\r\n",
        "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\r\n",
        "                            num_workers=get_dataloader_workers()),\r\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False,\r\n",
        "                            num_workers=get_dataloader_workers()))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "def accuracy(y_hat, y):\r\n",
        "    \"\"\"计算预测正确的数量。\"\"\"\r\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\r\n",
        "        y_hat = d2l.argmax(y_hat, axis=1)\r\n",
        "    cmp = d2l.astype(y_hat, y.dtype) == y\r\n",
        "    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "def evaluate_accuracy(net, data_iter):\r\n",
        "    \"\"\"计算在指定数据集上模型的精度。\"\"\"\r\n",
        "    if isinstance(net, torch.nn.Module):\r\n",
        "        net.eval()  # 将模型设置为评估模式\r\n",
        "    metric = Accumulator(2)  # 正确预测数、预测总数\r\n",
        "    for X, y in data_iter:\r\n",
        "        metric.add(accuracy(net(X), y), d2l.size(y))\r\n",
        "    return metric[0] / metric[1]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "class Accumulator:\r\n",
        "    \"\"\"在`n`个变量上累加。\"\"\"\r\n",
        "    def __init__(self, n):\r\n",
        "        self.data = [0.0] * n\r\n",
        "\r\n",
        "    def add(self, *args):\r\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.data = [0.0] * len(self.data)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        return self.data[idx]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "def train_epoch_ch3(net, train_iter, loss, updater):\r\n",
        "    \"\"\"训练模型一个迭代周期（定义见第3章）。\"\"\"\r\n",
        "    # 将模型设置为训练模式\r\n",
        "    if isinstance(net, torch.nn.Module):\r\n",
        "        net.train()\r\n",
        "    # 训练损失总和、训练准确度总和、样本数\r\n",
        "    metric = Accumulator(3)\r\n",
        "    for X, y in train_iter:\r\n",
        "        # 计算梯度并更新参数\r\n",
        "        y_hat = net(X)\r\n",
        "        l = loss(y_hat, y)\r\n",
        "        if isinstance(updater, torch.optim.Optimizer):\r\n",
        "            # 使用PyTorch内置的优化器和损失函数\r\n",
        "            updater.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            updater.step()\r\n",
        "            metric.add(\r\n",
        "                float(l) * len(y), accuracy(y_hat, y),\r\n",
        "                y.size().numel())\r\n",
        "        else:\r\n",
        "            # 使用PyTorch内置的优化器和损失函数\r\n",
        "            l.sum().backward()\r\n",
        "            updater(X.shape[0])\r\n",
        "            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\r\n",
        "    # 返回训练损失和训练准确率\r\n",
        "    return metric[0] / metric[2], metric[1] / metric[2]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "class Animator:\r\n",
        "    \"\"\"在动画中绘制数据。\"\"\"\r\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\r\n",
        "                 ylim=None, xscale='linear', yscale='linear',\r\n",
        "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\r\n",
        "                 figsize=(3.5, 2.5)):\r\n",
        "        # 增量地绘制多条线\r\n",
        "        if legend is None:\r\n",
        "            legend = []\r\n",
        "        d2l.use_svg_display()\r\n",
        "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\r\n",
        "        if nrows * ncols == 1:\r\n",
        "            self.axes = [self.axes,]\r\n",
        "        # 使用lambda函数捕获参数\r\n",
        "        self.config_axes = lambda: d2l.set_axes(self.axes[\r\n",
        "            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\r\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\r\n",
        "\r\n",
        "    def add(self, x, y):\r\n",
        "        # 向图表中添加多个数据点\r\n",
        "        if not hasattr(y, \"__len__\"):\r\n",
        "            y = [y]\r\n",
        "        n = len(y)\r\n",
        "        if not hasattr(x, \"__len__\"):\r\n",
        "            x = [x] * n\r\n",
        "        if not self.X:\r\n",
        "            self.X = [[] for _ in range(n)]\r\n",
        "        if not self.Y:\r\n",
        "            self.Y = [[] for _ in range(n)]\r\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\r\n",
        "            if a is not None and b is not None:\r\n",
        "                self.X[i].append(a)\r\n",
        "                self.Y[i].append(b)\r\n",
        "        self.axes[0].cla()\r\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\r\n",
        "            self.axes[0].plot(x, y, fmt)\r\n",
        "        self.config_axes()\r\n",
        "        display.display(self.fig)\r\n",
        "        display.clear_output(wait=True)\r\n",
        "\r\n",
        "\r\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\r\n",
        "              params=None, lr=None, optimizer=None):\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\r\n",
        "        for X, y in train_iter:\r\n",
        "            y_hat = net(X)\r\n",
        "            l = loss(y_hat, y).sum()\r\n",
        "            \r\n",
        "            # 梯度清零\r\n",
        "            if optimizer is not None:\r\n",
        "                optimizer.zero_grad()\r\n",
        "            elif params is not None and params[0].grad is not None:\r\n",
        "                for param in params:\r\n",
        "                    param.grad.data.zero_()\r\n",
        "            \r\n",
        "            l.backward()\r\n",
        "            if optimizer is None:\r\n",
        "                sgd(params, lr, batch_size)\r\n",
        "            else:\r\n",
        "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\r\n",
        "            \r\n",
        "            \r\n",
        "            train_l_sum += l.item()\r\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\r\n",
        "            n += y.shape[0]\r\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\r\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\r\n",
        "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_linear-networks/softmax-regression-scratch.md\r\n",
        "def predict_ch3(net, test_iter, n=6):\r\n",
        "    \"\"\"预测标签（定义见第3章）。\"\"\"\r\n",
        "    for X, y in test_iter:\r\n",
        "        break\r\n",
        "    trues = d2l.get_fashion_mnist_labels(y)\r\n",
        "    preds = d2l.get_fashion_mnist_labels(d2l.argmax(net(X), axis=1))\r\n",
        "    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\r\n",
        "    d2l.show_images(d2l.reshape(X[0:n], (n, 28, 28)), 1, n,\r\n",
        "                    titles=titles[0:n])\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_multilayer-perceptrons/underfit-overfit.md\r\n",
        "def evaluate_loss(net, data_iter, loss):\r\n",
        "    \"\"\"评估给定数据集上模型的损失。\"\"\"\r\n",
        "    metric = d2l.Accumulator(2)  # 损失的总和, 样本数量\r\n",
        "    for X, y in data_iter:\r\n",
        "        out = net(X)\r\n",
        "        y = d2l.reshape(y, out.shape)\r\n",
        "        l = loss(out, y)\r\n",
        "        metric.add(d2l.reduce_sum(l), d2l.size(l))\r\n",
        "    return metric[0] / metric[1]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_multilayer-perceptrons/kaggle-house-price.md\r\n",
        "DATA_HUB = dict()\r\n",
        "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_multilayer-perceptrons/kaggle-house-price.md\r\n",
        "def download(name, cache_dir=os.path.join('..', 'data')):\r\n",
        "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名。\"\"\"\r\n",
        "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}.\"\r\n",
        "    url, sha1_hash = DATA_HUB[name]\r\n",
        "    os.makedirs(cache_dir, exist_ok=True)\r\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\r\n",
        "    if os.path.exists(fname):\r\n",
        "        sha1 = hashlib.sha1()\r\n",
        "        with open(fname, 'rb') as f:\r\n",
        "            while True:\r\n",
        "                data = f.read(1048576)\r\n",
        "                if not data:\r\n",
        "                    break\r\n",
        "                sha1.update(data)\r\n",
        "        if sha1.hexdigest() == sha1_hash:\r\n",
        "            return fname  # Hit cache\r\n",
        "    print(f'正在从{url}下载{fname}...')\r\n",
        "    r = requests.get(url, stream=True, verify=True)\r\n",
        "    with open(fname, 'wb') as f:\r\n",
        "        f.write(r.content)\r\n",
        "    return fname\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_multilayer-perceptrons/kaggle-house-price.md\r\n",
        "def download_extract(name, folder=None):\r\n",
        "    \"\"\"下载并解压zip/tar文件。\"\"\"\r\n",
        "    fname = download(name)\r\n",
        "    base_dir = os.path.dirname(fname)\r\n",
        "    data_dir, ext = os.path.splitext(fname)\r\n",
        "    if ext == '.zip':\r\n",
        "        fp = zipfile.ZipFile(fname, 'r')\r\n",
        "    elif ext in ('.tar', '.gz'):\r\n",
        "        fp = tarfile.open(fname, 'r')\r\n",
        "    else:\r\n",
        "        assert False, '只有zip/tar文件可以被解压缩。'\r\n",
        "    fp.extractall(base_dir)\r\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\r\n",
        "\r\n",
        "def download_all():\r\n",
        "    \"\"\"下载DATA_HUB中的所有文件。\"\"\"\r\n",
        "    for name in DATA_HUB:\r\n",
        "        download(name)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_multilayer-perceptrons/kaggle-house-price.md\r\n",
        "DATA_HUB['kaggle_house_train'] = (DATA_URL + 'kaggle_house_pred_train.csv',\r\n",
        "                                  '585e9cc93e70b39160e7921475f9bcd7d31219ce')\r\n",
        "\r\n",
        "DATA_HUB['kaggle_house_test'] = (DATA_URL + 'kaggle_house_pred_test.csv',\r\n",
        "                                 'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_deep-learning-computation/use-gpu.md\r\n",
        "def try_gpu(i=0):\r\n",
        "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\"\"\"\r\n",
        "    if torch.cuda.device_count() >= i + 1:\r\n",
        "        return torch.device(f'cuda:{i}')\r\n",
        "    return torch.device('cpu')\r\n",
        "\r\n",
        "def try_all_gpus():\r\n",
        "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。\"\"\"\r\n",
        "    devices = [\r\n",
        "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\r\n",
        "    return devices if devices else [torch.device('cpu')]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_convolutional-neural-networks/conv-layer.md\r\n",
        "def corr2d(X, K):\r\n",
        "    \"\"\"计算二维互相关运算。\"\"\"\r\n",
        "    h, w = K.shape\r\n",
        "    Y = d2l.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\r\n",
        "    for i in range(Y.shape[0]):\r\n",
        "        for j in range(Y.shape[1]):\r\n",
        "            Y[i, j] = d2l.reduce_sum((X[i:i + h, j:j + w] * K))\r\n",
        "    return Y\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_convolutional-neural-networks/lenet.md\r\n",
        "def evaluate_accuracy_gpu(net, data_iter, device=None):\r\n",
        "    \"\"\"使用GPU计算模型在数据集上的精度。\"\"\"\r\n",
        "    if isinstance(net, torch.nn.Module):\r\n",
        "        net.eval()  # 设置为评估模式\r\n",
        "        if not device:\r\n",
        "            device = next(iter(net.parameters())).device\r\n",
        "    # 正确预测的数量，总预测的数量\r\n",
        "    metric = d2l.Accumulator(2)\r\n",
        "    for X, y in data_iter:\r\n",
        "        if isinstance(X, list):\r\n",
        "            # BERT微调所需的（之后将介绍）\r\n",
        "            X = [x.to(device) for x in X]\r\n",
        "        else:\r\n",
        "            X = X.to(device)\r\n",
        "        y = y.to(device)\r\n",
        "        metric.add(d2l.accuracy(net(X), y), d2l.size(y))\r\n",
        "    return metric[0] / metric[1]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_convolutional-neural-networks/lenet.md\r\n",
        "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\r\n",
        "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\r\n",
        "    def init_weights(m):\r\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\r\n",
        "            nn.init.xavier_uniform_(m.weight)\r\n",
        "\r\n",
        "    net.apply(init_weights)\r\n",
        "    print('training on', device)\r\n",
        "    net.to(device)\r\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\r\n",
        "    loss = nn.CrossEntropyLoss()\r\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\r\n",
        "                            legend=['train loss', 'train acc', 'test acc'])\r\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        # 训练损失之和，训练准确率之和，范例数\r\n",
        "        metric = d2l.Accumulator(3)\r\n",
        "        net.train()\r\n",
        "        for i, (X, y) in enumerate(train_iter):\r\n",
        "            timer.start()\r\n",
        "            optimizer.zero_grad()\r\n",
        "            X, y = X.to(device), y.to(device)\r\n",
        "            y_hat = net(X)\r\n",
        "            l = loss(y_hat, y)\r\n",
        "            l.backward()\r\n",
        "            optimizer.step()\r\n",
        "            with torch.no_grad():\r\n",
        "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\r\n",
        "            timer.stop()\r\n",
        "            train_l = metric[0] / metric[2]\r\n",
        "            train_acc = metric[1] / metric[2]\r\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\r\n",
        "                animator.add(epoch + (i + 1) / num_batches,\r\n",
        "                             (train_l, train_acc, None))\r\n",
        "        test_acc = evaluate_accuracy_gpu(net, test_iter)\r\n",
        "        animator.add(epoch + 1, (None, None, test_acc))\r\n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\r\n",
        "          f'test acc {test_acc:.3f}')\r\n",
        "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\r\n",
        "          f'on {str(device)}')\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_convolutional-modern/resnet.md\r\n",
        "class Residual(nn.Module):\r\n",
        "    def __init__(self, input_channels, num_channels, use_1x1conv=False,\r\n",
        "                 strides=1):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3,\r\n",
        "                               padding=1, stride=strides)\r\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3,\r\n",
        "                               padding=1)\r\n",
        "        if use_1x1conv:\r\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels,\r\n",
        "                                   kernel_size=1, stride=strides)\r\n",
        "        else:\r\n",
        "            self.conv3 = None\r\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\r\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\r\n",
        "        self.relu = nn.ReLU(inplace=True)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\r\n",
        "        Y = self.bn2(self.conv2(Y))\r\n",
        "        if self.conv3:\r\n",
        "            X = self.conv3(X)\r\n",
        "        Y += X\r\n",
        "        return F.relu(Y)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/text-preprocessing.md\r\n",
        "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\r\n",
        "                                '090b5e7e70c295757f55df93cb0a180b9691891a')\r\n",
        "\r\n",
        "def read_time_machine():\r\n",
        "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\r\n",
        "    with open(d2l.download('time_machine'), 'r') as f:\r\n",
        "        lines = f.readlines()\r\n",
        "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/text-preprocessing.md\r\n",
        "def tokenize(lines, token='word'):\r\n",
        "    \"\"\"Split text lines into word or character tokens.\"\"\"\r\n",
        "    if token == 'word':\r\n",
        "        return [line.split() for line in lines]\r\n",
        "    elif token == 'char':\r\n",
        "        return [list(line) for line in lines]\r\n",
        "    else:\r\n",
        "        print('ERROR: unknown token type: ' + token)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/text-preprocessing.md\r\n",
        "class Vocab:\r\n",
        "    \"\"\"Vocabulary for text.\"\"\"\r\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\r\n",
        "        if tokens is None:\r\n",
        "            tokens = []\r\n",
        "        if reserved_tokens is None:\r\n",
        "            reserved_tokens = []\r\n",
        "        # Sort according to frequencies\r\n",
        "        counter = count_corpus(tokens)\r\n",
        "        self.token_freqs = sorted(counter.items(), key=lambda x: x[0])\r\n",
        "        self.token_freqs.sort(key=lambda x: x[1], reverse=True)\r\n",
        "        # The index for the unknown token is 0\r\n",
        "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\r\n",
        "        uniq_tokens += [\r\n",
        "            token for token, freq in self.token_freqs\r\n",
        "            if freq >= min_freq and token not in uniq_tokens]\r\n",
        "        self.idx_to_token, self.token_to_idx = [], dict()\r\n",
        "        for token in uniq_tokens:\r\n",
        "            self.idx_to_token.append(token)\r\n",
        "            self.token_to_idx[token] = len(self.idx_to_token) - 1\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.idx_to_token)\r\n",
        "\r\n",
        "    def __getitem__(self, tokens):\r\n",
        "        if not isinstance(tokens, (list, tuple)):\r\n",
        "            return self.token_to_idx.get(tokens, self.unk)\r\n",
        "        return [self.__getitem__(token) for token in tokens]\r\n",
        "\r\n",
        "    def to_tokens(self, indices):\r\n",
        "        if not isinstance(indices, (list, tuple)):\r\n",
        "            return self.idx_to_token[indices]\r\n",
        "        return [self.idx_to_token[index] for index in indices]\r\n",
        "\r\n",
        "def count_corpus(tokens):\r\n",
        "    \"\"\"Count token frequencies.\"\"\"\r\n",
        "    # Here `tokens` is a 1D list or 2D list\r\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\r\n",
        "        # Flatten a list of token lists into a list of tokens\r\n",
        "        tokens = [token for line in tokens for token in line]\r\n",
        "    return collections.Counter(tokens)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/text-preprocessing.md\r\n",
        "def load_corpus_time_machine(max_tokens=-1):\r\n",
        "    \"\"\"Return token indices and the vocabulary of the time machine dataset.\"\"\"\r\n",
        "    lines = read_time_machine()\r\n",
        "    tokens = tokenize(lines, 'char')\r\n",
        "    vocab = Vocab(tokens)\r\n",
        "    # Since each text line in the time machine dataset is not necessarily a\r\n",
        "    # sentence or a paragraph, flatten all the text lines into a single list\r\n",
        "    corpus = [vocab[token] for line in tokens for token in line]\r\n",
        "    if max_tokens > 0:\r\n",
        "        corpus = corpus[:max_tokens]\r\n",
        "    return corpus, vocab\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/language-models-and-dataset.md\r\n",
        "def seq_data_iter_random(corpus, batch_size, num_steps):\r\n",
        "    \"\"\"Generate a minibatch of subsequences using random sampling.\"\"\"\r\n",
        "    # Start with a random offset to partition a sequence\r\n",
        "    corpus = corpus[random.randint(0, num_steps):]\r\n",
        "    # Subtract 1 since we need to account for labels\r\n",
        "    num_subseqs = (len(corpus) - 1) // num_steps\r\n",
        "    # The starting indices for subsequences of length `num_steps`\r\n",
        "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\r\n",
        "    # In random sampling, the subsequences from two adjacent random\r\n",
        "    # minibatches during iteration are not necessarily adjacent on the\r\n",
        "    # original sequence\r\n",
        "    random.shuffle(initial_indices)\r\n",
        "\r\n",
        "    def data(pos):\r\n",
        "        # Return a sequence of length `num_steps` starting from `pos`\r\n",
        "        return corpus[pos:pos + num_steps]\r\n",
        "\r\n",
        "    num_subseqs_per_example = num_subseqs // batch_size\r\n",
        "    for i in range(0, batch_size * num_subseqs_per_example, batch_size):\r\n",
        "        # Here, `initial_indices` contains randomized starting indices for\r\n",
        "        # subsequences\r\n",
        "        initial_indices_per_batch = initial_indices[i:i + batch_size]\r\n",
        "        X = [data(j) for j in initial_indices_per_batch]\r\n",
        "        Y = [data(j + 1) for j in initial_indices_per_batch]\r\n",
        "        yield d2l.tensor(X), d2l.tensor(Y)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/language-models-and-dataset.md\r\n",
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\r\n",
        "    \"\"\"Generate a minibatch of subsequences using sequential partitioning.\"\"\"\r\n",
        "    # Start with a random offset to partition a sequence\r\n",
        "    offset = random.randint(0, num_steps)\r\n",
        "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\r\n",
        "    Xs = d2l.tensor(corpus[offset:offset + num_tokens])\r\n",
        "    Ys = d2l.tensor(corpus[offset + 1:offset + 1 + num_tokens])\r\n",
        "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\r\n",
        "    num_batches = Xs.shape[1] // num_steps\r\n",
        "    for i in range(0, num_batches * num_steps, num_steps):\r\n",
        "        X = Xs[:, i:i + num_steps]\r\n",
        "        Y = Ys[:, i:i + num_steps]\r\n",
        "        yield X, Y\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/language-models-and-dataset.md\r\n",
        "class SeqDataLoader:\r\n",
        "    \"\"\"An iterator to load sequence data.\"\"\"\r\n",
        "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\r\n",
        "        if use_random_iter:\r\n",
        "            self.data_iter_fn = d2l.seq_data_iter_random\r\n",
        "        else:\r\n",
        "            self.data_iter_fn = d2l.seq_data_iter_sequential\r\n",
        "        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\r\n",
        "        self.batch_size, self.num_steps = batch_size, num_steps\r\n",
        "\r\n",
        "    def __iter__(self):\r\n",
        "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/language-models-and-dataset.md\r\n",
        "def load_data_time_machine(batch_size, num_steps, use_random_iter=False,\r\n",
        "                           max_tokens=10000):\r\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\r\n",
        "    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter,\r\n",
        "                              max_tokens)\r\n",
        "    return data_iter, data_iter.vocab\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-scratch.md\r\n",
        "class RNNModelScratch:\r\n",
        "    \"\"\"A RNN Model implemented from scratch.\"\"\"\r\n",
        "    def __init__(self, vocab_size, num_hiddens, device, get_params,\r\n",
        "                 init_state, forward_fn):\r\n",
        "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\r\n",
        "        self.params = get_params(vocab_size, num_hiddens, device)\r\n",
        "        self.init_state, self.forward_fn = init_state, forward_fn\r\n",
        "\r\n",
        "    def __call__(self, X, state):\r\n",
        "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\r\n",
        "        return self.forward_fn(X, state, self.params)\r\n",
        "\r\n",
        "    def begin_state(self, batch_size, device):\r\n",
        "        return self.init_state(batch_size, self.num_hiddens, device)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-scratch.md\r\n",
        "def predict_ch8(prefix, num_preds, model, vocab, device):\r\n",
        "    \"\"\"Generate new characters following the `prefix`.\"\"\"\r\n",
        "    state = model.begin_state(batch_size=1, device=device)\r\n",
        "    outputs = [vocab[prefix[0]]]\r\n",
        "    get_input = lambda: d2l.reshape(d2l.tensor([outputs[-1]], device=device),\r\n",
        "                                    (1, 1))\r\n",
        "    for y in prefix[1:]:  # Warm-up period\r\n",
        "        _, state = model(get_input(), state)\r\n",
        "        outputs.append(vocab[y])\r\n",
        "    for _ in range(num_preds):  # Predict `num_preds` steps\r\n",
        "        y, state = model(get_input(), state)\r\n",
        "        outputs.append(int(y.argmax(dim=1).reshape(1)))\r\n",
        "    return ''.join([vocab.idx_to_token[i] for i in outputs])\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-scratch.md\r\n",
        "def grad_clipping(model, theta):\r\n",
        "    \"\"\"Clip the gradient.\"\"\"\r\n",
        "    if isinstance(model, nn.Module):\r\n",
        "        params = [p for p in model.parameters() if p.requires_grad]\r\n",
        "    else:\r\n",
        "        params = model.params\r\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\r\n",
        "    if norm > theta:\r\n",
        "        for param in params:\r\n",
        "            param.grad[:] *= theta / norm\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-scratch.md\r\n",
        "def train_epoch_ch8(model, train_iter, loss, updater, device,\r\n",
        "                    use_random_iter):\r\n",
        "    \"\"\"Train a model within one epoch (defined in Chapter 8).\"\"\"\r\n",
        "    state, timer = None, d2l.Timer()\r\n",
        "    metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\r\n",
        "    for X, Y in train_iter:\r\n",
        "        if state is None or use_random_iter:\r\n",
        "            # Initialize `state` when either it is the first iteration or\r\n",
        "            # using random sampling\r\n",
        "            state = model.begin_state(batch_size=X.shape[0], device=device)\r\n",
        "        else:\r\n",
        "            if isinstance(model, nn.Module) and not isinstance(state, tuple):\r\n",
        "                # `state` is a tensor for `nn.GRU`\r\n",
        "                state.detach_()\r\n",
        "            else:\r\n",
        "                # `state` is a tuple of tensors for `nn.LSTM` and\r\n",
        "                # for our custom scratch implementation\r\n",
        "                for s in state:\r\n",
        "                    s.detach_()\r\n",
        "        y = Y.T.reshape(-1)\r\n",
        "        X, y = X.to(device), y.to(device)\r\n",
        "        y_hat, state = model(X, state)\r\n",
        "        l = loss(y_hat, y.long()).mean()\r\n",
        "        if isinstance(updater, torch.optim.Optimizer):\r\n",
        "            updater.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            grad_clipping(model, 1)\r\n",
        "            updater.step()\r\n",
        "        else:\r\n",
        "            l.backward()\r\n",
        "            grad_clipping(model, 1)\r\n",
        "            # Since the `mean` function has been invoked\r\n",
        "            updater(batch_size=1)\r\n",
        "        metric.add(l * d2l.size(y), d2l.size(y))\r\n",
        "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-scratch.md\r\n",
        "def train_ch8(model, train_iter, vocab, lr, num_epochs, device,\r\n",
        "              use_random_iter=False):\r\n",
        "    \"\"\"Train a model (defined in Chapter 8).\"\"\"\r\n",
        "    loss = nn.CrossEntropyLoss()\r\n",
        "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\r\n",
        "                            legend=['train'], xlim=[10, num_epochs])\r\n",
        "    # Initialize\r\n",
        "    if isinstance(model, nn.Module):\r\n",
        "        updater = torch.optim.SGD(model.parameters(), lr)\r\n",
        "    else:\r\n",
        "        updater = lambda batch_size: d2l.sgd(model.params, lr, batch_size)\r\n",
        "    predict = lambda prefix: predict_ch8(prefix, 50, model, vocab, device)\r\n",
        "    # Train and predict\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        ppl, speed = train_epoch_ch8(model, train_iter, loss, updater, device,\r\n",
        "                                     use_random_iter)\r\n",
        "        if (epoch + 1) % 10 == 0:\r\n",
        "            print(predict('time traveller'))\r\n",
        "            animator.add(epoch + 1, [ppl])\r\n",
        "    print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\r\n",
        "    print(predict('time traveller'))\r\n",
        "    print(predict('traveller'))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-neural-networks/rnn-concise.md\r\n",
        "class RNNModel(nn.Module):\r\n",
        "    \"\"\"The RNN model.\"\"\"\r\n",
        "    def __init__(self, rnn_layer, vocab_size, **kwargs):\r\n",
        "        super(RNNModel, self).__init__(**kwargs)\r\n",
        "        self.rnn = rnn_layer\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.num_hiddens = self.rnn.hidden_size\r\n",
        "        # If the RNN is bidirectional (to be introduced later),\r\n",
        "        # `num_directions` should be 2, else it should be 1.\r\n",
        "        if not self.rnn.bidirectional:\r\n",
        "            self.num_directions = 1\r\n",
        "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\r\n",
        "        else:\r\n",
        "            self.num_directions = 2\r\n",
        "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\r\n",
        "\r\n",
        "    def forward(self, inputs, state):\r\n",
        "        X = F.one_hot(inputs.T.long(), self.vocab_size)\r\n",
        "        X = X.to(torch.float32)\r\n",
        "        Y, state = self.rnn(X, state)\r\n",
        "        # The fully connected layer will first change the shape of `Y` to\r\n",
        "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\r\n",
        "        # (`num_steps` * `batch_size`, `vocab_size`).\r\n",
        "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\r\n",
        "        return output, state\r\n",
        "\r\n",
        "    def begin_state(self, device, batch_size=1):\r\n",
        "        if not isinstance(self.rnn, nn.LSTM):\r\n",
        "            # `nn.GRU` takes a tensor as hidden state\r\n",
        "            return torch.zeros((self.num_directions * self.rnn.num_layers,\r\n",
        "                                batch_size, self.num_hiddens), device=device)\r\n",
        "        else:\r\n",
        "            # `nn.LSTM` takes a tuple of hidden states\r\n",
        "            return (torch.zeros((self.num_directions * self.rnn.num_layers,\r\n",
        "                                 batch_size, self.num_hiddens),\r\n",
        "                                device=device),\r\n",
        "                    torch.zeros((self.num_directions * self.rnn.num_layers,\r\n",
        "                                 batch_size, self.num_hiddens),\r\n",
        "                                device=device))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\r\n",
        "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\r\n",
        "\r\n",
        "def read_data_nmt():\r\n",
        "    \"\"\"Load the English-French dataset.\"\"\"\r\n",
        "    data_dir = d2l.download_extract('fra-eng')\r\n",
        "    with open(os.path.join(data_dir, 'fra.txt'), 'r') as f:\r\n",
        "        return f.read()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "def preprocess_nmt(text):\r\n",
        "    \"\"\"Preprocess the English-French dataset.\"\"\"\r\n",
        "    def no_space(char, prev_char):\r\n",
        "        return char in set(',.!?') and prev_char != ' '\r\n",
        "\r\n",
        "    # Replace non-breaking space with space, and convert uppercase letters to\r\n",
        "    # lowercase ones\r\n",
        "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\r\n",
        "    # Insert space between words and punctuation marks\r\n",
        "    out = [\r\n",
        "        ' ' + char if i > 0 and no_space(char, text[i - 1]) else char\r\n",
        "        for i, char in enumerate(text)]\r\n",
        "    return ''.join(out)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "def tokenize_nmt(text, num_examples=None):\r\n",
        "    \"\"\"Tokenize the English-French dataset.\"\"\"\r\n",
        "    source, target = [], []\r\n",
        "    for i, line in enumerate(text.split('\\n')):\r\n",
        "        if num_examples and i > num_examples:\r\n",
        "            break\r\n",
        "        parts = line.split('\\t')\r\n",
        "        if len(parts) == 2:\r\n",
        "            source.append(parts[0].split(' '))\r\n",
        "            target.append(parts[1].split(' '))\r\n",
        "    return source, target\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "def truncate_pad(line, num_steps, padding_token):\r\n",
        "    \"\"\"Truncate or pad sequences.\"\"\"\r\n",
        "    if len(line) > num_steps:\r\n",
        "        return line[:num_steps]  # Truncate\r\n",
        "    return line + [padding_token] * (num_steps - len(line))  # Pad\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "def build_array_nmt(lines, vocab, num_steps):\r\n",
        "    \"\"\"Transform text sequences of machine translation into minibatches.\"\"\"\r\n",
        "    lines = [vocab[l] for l in lines]\r\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\r\n",
        "    array = d2l.tensor([\r\n",
        "        truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\r\n",
        "    valid_len = d2l.reduce_sum(d2l.astype(array != vocab['<pad>'], d2l.int32),\r\n",
        "                               1)\r\n",
        "    return array, valid_len\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/machine-translation-and-dataset.md\r\n",
        "def load_data_nmt(batch_size, num_steps, num_examples=600):\r\n",
        "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\r\n",
        "    text = preprocess_nmt(read_data_nmt())\r\n",
        "    source, target = tokenize_nmt(text, num_examples)\r\n",
        "    src_vocab = d2l.Vocab(source, min_freq=2,\r\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\r\n",
        "    tgt_vocab = d2l.Vocab(target, min_freq=2,\r\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\r\n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\r\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\r\n",
        "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\r\n",
        "    data_iter = d2l.load_array(data_arrays, batch_size)\r\n",
        "    return data_iter, src_vocab, tgt_vocab\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/encoder-decoder.md\r\n",
        "class Encoder(nn.Module):\r\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(Encoder, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    def forward(self, X, *args):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/encoder-decoder.md\r\n",
        "class Decoder(nn.Module):\r\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(Decoder, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    def init_state(self, enc_outputs, *args):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def forward(self, X, state):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/encoder-decoder.md\r\n",
        "class EncoderDecoder(nn.Module):\r\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\r\n",
        "    def __init__(self, encoder, decoder, **kwargs):\r\n",
        "        super(EncoderDecoder, self).__init__(**kwargs)\r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "\r\n",
        "    def forward(self, enc_X, dec_X, *args):\r\n",
        "        enc_outputs = self.encoder(enc_X, *args)\r\n",
        "        dec_state = self.decoder.init_state(enc_outputs, *args)\r\n",
        "        return self.decoder(dec_X, dec_state)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "class Seq2SeqEncoder(d2l.Encoder):\r\n",
        "    \"\"\"The RNN encoder for sequence to sequence learning.\"\"\"\r\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\r\n",
        "                 dropout=0, **kwargs):\r\n",
        "        super(Seq2SeqEncoder, self).__init__(**kwargs)\r\n",
        "        # Embedding layer\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\r\n",
        "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\r\n",
        "                          dropout=dropout)\r\n",
        "\r\n",
        "    def forward(self, X, *args):\r\n",
        "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\r\n",
        "        X = self.embedding(X)\r\n",
        "        # In RNN models, the first axis corresponds to time steps\r\n",
        "        X = X.permute(1, 0, 2)\r\n",
        "        # When state is not mentioned, it defaults to zeros\r\n",
        "        output, state = self.rnn(X)\r\n",
        "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\r\n",
        "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\r\n",
        "        return output, state\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "def sequence_mask(X, valid_len, value=0):\r\n",
        "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\r\n",
        "    maxlen = X.size(1)\r\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\r\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\r\n",
        "    X[~mask] = value\r\n",
        "    return X\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\r\n",
        "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\r\n",
        "\r\n",
        "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\r\n",
        "    # `label` shape: (`batch_size`, `num_steps`)\r\n",
        "    # `valid_len` shape: (`batch_size`,)\r\n",
        "    def forward(self, pred, label, valid_len):\r\n",
        "        weights = torch.ones_like(label)\r\n",
        "        weights = sequence_mask(weights, valid_len)\r\n",
        "        self.reduction = 'none'\r\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss,\r\n",
        "                                self).forward(pred.permute(0, 2, 1), label)\r\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\r\n",
        "        return weighted_loss\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\r\n",
        "    \"\"\"Train a model for sequence to sequence.\"\"\"\r\n",
        "    def xavier_init_weights(m):\r\n",
        "        if type(m) == nn.Linear:\r\n",
        "            nn.init.xavier_uniform_(m.weight)\r\n",
        "        if type(m) == nn.GRU:\r\n",
        "            for param in m._flat_weights_names:\r\n",
        "                if \"weight\" in param:\r\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\r\n",
        "\r\n",
        "    net.apply(xavier_init_weights)\r\n",
        "    net.to(device)\r\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\r\n",
        "    loss = MaskedSoftmaxCELoss()\r\n",
        "    net.train()\r\n",
        "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\r\n",
        "                            xlim=[10, num_epochs])\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        timer = d2l.Timer()\r\n",
        "        metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\r\n",
        "        for batch in data_iter:\r\n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\r\n",
        "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\r\n",
        "                               device=device).reshape(-1, 1)\r\n",
        "            dec_input = d2l.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\r\n",
        "            Y_hat, _ = net(X, dec_input, X_valid_len)\r\n",
        "            l = loss(Y_hat, Y, Y_valid_len)\r\n",
        "            l.sum().backward()  # Make the loss scalar for `backward`\r\n",
        "            d2l.grad_clipping(net, 1)\r\n",
        "            num_tokens = Y_valid_len.sum()\r\n",
        "            optimizer.step()\r\n",
        "            with torch.no_grad():\r\n",
        "                metric.add(l.sum(), num_tokens)\r\n",
        "        if (epoch + 1) % 10 == 0:\r\n",
        "            animator.add(epoch + 1, (metric[0] / metric[1],))\r\n",
        "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\r\n",
        "          f'tokens/sec on {str(device)}')\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\r\n",
        "                    device, save_attention_weights=False):\r\n",
        "    \"\"\"Predict for sequence to sequence.\"\"\"\r\n",
        "    # Set `net` to eval mode for inference\r\n",
        "    net.eval()\r\n",
        "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\r\n",
        "        src_vocab['<eos>']]\r\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\r\n",
        "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\r\n",
        "    # Add the batch axis\r\n",
        "    enc_X = torch.unsqueeze(\r\n",
        "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\r\n",
        "    enc_outputs = net.encoder(enc_X, enc_valid_len)\r\n",
        "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\r\n",
        "    # Add the batch axis\r\n",
        "    dec_X = torch.unsqueeze(\r\n",
        "        torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device),\r\n",
        "        dim=0)\r\n",
        "    output_seq, attention_weight_seq = [], []\r\n",
        "    for _ in range(num_steps):\r\n",
        "        Y, dec_state = net.decoder(dec_X, dec_state)\r\n",
        "        # We use the token with the highest prediction likelihood as the input\r\n",
        "        # of the decoder at the next time step\r\n",
        "        dec_X = Y.argmax(dim=2)\r\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\r\n",
        "        # Save attention weights (to be covered later)\r\n",
        "        if save_attention_weights:\r\n",
        "            attention_weight_seq.append(net.decoder.attention_weights)\r\n",
        "        # Once the end-of-sequence token is predicted, the generation of the\r\n",
        "        # output sequence is complete\r\n",
        "        if pred == tgt_vocab['<eos>']:\r\n",
        "            break\r\n",
        "        output_seq.append(pred)\r\n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_recurrent-modern/seq2seq.md\r\n",
        "def bleu(pred_seq, label_seq, k):\r\n",
        "    \"\"\"Compute the BLEU.\"\"\"\r\n",
        "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\r\n",
        "    len_pred, len_label = len(pred_tokens), len(label_tokens)\r\n",
        "    score = math.exp(min(0, 1 - len_label / len_pred))\r\n",
        "    for n in range(1, k + 1):\r\n",
        "        num_matches, label_subs = 0, collections.defaultdict(int)\r\n",
        "        for i in range(len_label - n + 1):\r\n",
        "            label_subs[''.join(label_tokens[i:i + n])] += 1\r\n",
        "        for i in range(len_pred - n + 1):\r\n",
        "            if label_subs[''.join(pred_tokens[i:i + n])] > 0:\r\n",
        "                num_matches += 1\r\n",
        "                label_subs[''.join(pred_tokens[i:i + n])] -= 1\r\n",
        "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\r\n",
        "    return score\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/attention-cues.md\r\n",
        "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\r\n",
        "                  cmap='Reds'):\r\n",
        "    d2l.use_svg_display()\r\n",
        "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\r\n",
        "    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,\r\n",
        "                                 sharex=True, sharey=True, squeeze=False)\r\n",
        "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\r\n",
        "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\r\n",
        "            pcm = ax.imshow(d2l.numpy(matrix), cmap=cmap)\r\n",
        "            if i == num_rows - 1:\r\n",
        "                ax.set_xlabel(xlabel)\r\n",
        "            if j == 0:\r\n",
        "                ax.set_ylabel(ylabel)\r\n",
        "            if titles:\r\n",
        "                ax.set_title(titles[j])\r\n",
        "    fig.colorbar(pcm, ax=axes, shrink=0.6)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/attention-scoring-functions.md\r\n",
        "def masked_softmax(X, valid_lens):\r\n",
        "    \"\"\"Perform softmax operation by masking elements on the last axis.\"\"\"\r\n",
        "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\r\n",
        "    if valid_lens is None:\r\n",
        "        return nn.functional.softmax(X, dim=-1)\r\n",
        "    else:\r\n",
        "        shape = X.shape\r\n",
        "        if valid_lens.dim() == 1:\r\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\r\n",
        "        else:\r\n",
        "            valid_lens = valid_lens.reshape(-1)\r\n",
        "        # On the last axis, replace masked elements with a very large negative\r\n",
        "        # value, whose exponentiation outputs 0\r\n",
        "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\r\n",
        "                              value=-1e6)\r\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/attention-scoring-functions.md\r\n",
        "class AdditiveAttention(nn.Module):\r\n",
        "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\r\n",
        "        super(AdditiveAttention, self).__init__(**kwargs)\r\n",
        "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\r\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\r\n",
        "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "    def forward(self, queries, keys, values, valid_lens):\r\n",
        "        queries, keys = self.W_q(queries), self.W_k(keys)\r\n",
        "        # After dimension expansion, shape of `queries`: (`batch_size`, no. of\r\n",
        "        # queries, 1, `num_hiddens`) and shape of `keys`: (`batch_size`, 1,\r\n",
        "        # no. of key-value pairs, `num_hiddens`). Sum them up with\r\n",
        "        # broadcasting\r\n",
        "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\r\n",
        "        features = torch.tanh(features)\r\n",
        "        # There is only one output of `self.w_v`, so we remove the last\r\n",
        "        # one-dimensional entry from the shape. Shape of `scores`:\r\n",
        "        # (`batch_size`, no. of queries, no. of key-value pairs)\r\n",
        "        scores = self.w_v(features).squeeze(-1)\r\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\r\n",
        "        # Shape of `values`: (`batch_size`, no. of key-value pairs, value\r\n",
        "        # dimension)\r\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/attention-scoring-functions.md\r\n",
        "class DotProductAttention(nn.Module):\r\n",
        "    \"\"\"Scaled dot product attention.\"\"\"\r\n",
        "    def __init__(self, dropout, **kwargs):\r\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "    # Shape of `queries`: (`batch_size`, no. of queries, `d`)\r\n",
        "    # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\r\n",
        "    # Shape of `values`: (`batch_size`, no. of key-value pairs, value\r\n",
        "    # dimension)\r\n",
        "    # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\r\n",
        "    def forward(self, queries, keys, values, valid_lens=None):\r\n",
        "        d = queries.shape[-1]\r\n",
        "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\r\n",
        "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\r\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\r\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/bahdanau-attention.md\r\n",
        "class AttentionDecoder(d2l.Decoder):\r\n",
        "    \"\"\"The base attention-based decoder interface.\"\"\"\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    @property\r\n",
        "    def attention_weights(self):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/multihead-attention.md\r\n",
        "class MultiHeadAttention(nn.Module):\r\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\r\n",
        "                 num_heads, dropout, bias=False, **kwargs):\r\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\r\n",
        "        self.num_heads = num_heads\r\n",
        "        self.attention = d2l.DotProductAttention(dropout)\r\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\r\n",
        "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\r\n",
        "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\r\n",
        "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\r\n",
        "\r\n",
        "    def forward(self, queries, keys, values, valid_lens):\r\n",
        "        # Shape of `queries`, `keys`, or `values`:\r\n",
        "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\r\n",
        "        # Shape of `valid_lens`:\r\n",
        "        # (`batch_size`,) or (`batch_size`, no. of queries)\r\n",
        "        # After transposing, shape of output `queries`, `keys`, or `values`:\r\n",
        "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\r\n",
        "        # `num_hiddens` / `num_heads`)\r\n",
        "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\r\n",
        "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\r\n",
        "        values = transpose_qkv(self.W_v(values), self.num_heads)\r\n",
        "\r\n",
        "        if valid_lens is not None:\r\n",
        "            # On axis 0, copy the first item (scalar or vector) for\r\n",
        "            # `num_heads` times, then copy the next item, and so on\r\n",
        "            valid_lens = torch.repeat_interleave(valid_lens,\r\n",
        "                                                 repeats=self.num_heads,\r\n",
        "                                                 dim=0)\r\n",
        "\r\n",
        "        # Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\r\n",
        "        # `num_hiddens` / `num_heads`)\r\n",
        "        output = self.attention(queries, keys, values, valid_lens)\r\n",
        "\r\n",
        "        # Shape of `output_concat`:\r\n",
        "        # (`batch_size`, no. of queries, `num_hiddens`)\r\n",
        "        output_concat = transpose_output(output, self.num_heads)\r\n",
        "        return self.W_o(output_concat)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/multihead-attention.md\r\n",
        "def transpose_qkv(X, num_heads):\r\n",
        "    # Shape of input `X`:\r\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\r\n",
        "    # Shape of output `X`:\r\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_heads`,\r\n",
        "    # `num_hiddens` / `num_heads`)\r\n",
        "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\r\n",
        "\r\n",
        "    # Shape of output `X`:\r\n",
        "    # (`batch_size`, `num_heads`, no. of queries or key-value pairs,\r\n",
        "    # `num_hiddens` / `num_heads`)\r\n",
        "    X = X.permute(0, 2, 1, 3)\r\n",
        "\r\n",
        "    # Shape of `output`:\r\n",
        "    # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\r\n",
        "    # `num_hiddens` / `num_heads`)\r\n",
        "    return X.reshape(-1, X.shape[2], X.shape[3])\r\n",
        "\r\n",
        "def transpose_output(X, num_heads):\r\n",
        "    \"\"\"Reverse the operation of `transpose_qkv`\"\"\"\r\n",
        "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\r\n",
        "    X = X.permute(0, 2, 1, 3)\r\n",
        "    return X.reshape(X.shape[0], X.shape[1], -1)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/self-attention-and-positional-encoding.md\r\n",
        "class PositionalEncoding(nn.Module):\r\n",
        "    def __init__(self, num_hiddens, dropout, max_len=1000):\r\n",
        "        super(PositionalEncoding, self).__init__()\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        # Create a long enough `P`\r\n",
        "        self.P = d2l.zeros((1, max_len, num_hiddens))\r\n",
        "        X = d2l.arange(max_len, dtype=torch.float32).reshape(\r\n",
        "            -1, 1) / torch.pow(\r\n",
        "                10000,\r\n",
        "                torch.arange(0, num_hiddens, 2, dtype=torch.float32) /\r\n",
        "                num_hiddens)\r\n",
        "        self.P[:, :, 0::2] = torch.sin(X)\r\n",
        "        self.P[:, :, 1::2] = torch.cos(X)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        X = X + self.P[:, :X.shape[1], :].to(X.device)\r\n",
        "        return self.dropout(X)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/transformer.md\r\n",
        "class PositionWiseFFN(nn.Module):\r\n",
        "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\r\n",
        "                 **kwargs):\r\n",
        "        super(PositionWiseFFN, self).__init__(**kwargs)\r\n",
        "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        return self.dense2(self.relu(self.dense1(X)))\r\n",
        "\r\n",
        "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\r\n",
        "             legend=None, figsize=(3.5, 2.5)):\r\n",
        "    set_figsize(figsize)\r\n",
        "    plt.xlabel(x_label)\r\n",
        "    plt.ylabel(y_label)\r\n",
        "    plt.semilogy(x_vals, y_vals)\r\n",
        "    if x2_vals and y2_vals:\r\n",
        "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\r\n",
        "        plt.legend(legend)\r\n",
        "    # plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/transformer.md\r\n",
        "class AddNorm(nn.Module):\r\n",
        "    def __init__(self, normalized_shape, dropout, **kwargs):\r\n",
        "        super(AddNorm, self).__init__(**kwargs)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        self.ln = nn.LayerNorm(normalized_shape)\r\n",
        "\r\n",
        "    def forward(self, X, Y):\r\n",
        "        return self.ln(self.dropout(Y) + X)\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/transformer.md\r\n",
        "class EncoderBlock(nn.Module):\r\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\r\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\r\n",
        "                 dropout, use_bias=False, **kwargs):\r\n",
        "        super(EncoderBlock, self).__init__(**kwargs)\r\n",
        "        self.attention = d2l.MultiHeadAttention(key_size, query_size,\r\n",
        "                                                value_size, num_hiddens,\r\n",
        "                                                num_heads, dropout, use_bias)\r\n",
        "        self.addnorm1 = AddNorm(norm_shape, dropout)\r\n",
        "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\r\n",
        "                                   num_hiddens)\r\n",
        "        self.addnorm2 = AddNorm(norm_shape, dropout)\r\n",
        "\r\n",
        "    def forward(self, X, valid_lens):\r\n",
        "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\r\n",
        "        return self.addnorm2(Y, self.ffn(Y))\r\n",
        "\r\n",
        "\r\n",
        "# Defined in file: ./chapter_attention-mechanisms/transformer.md\r\n",
        "class TransformerEncoder(d2l.Encoder):\r\n",
        "    def __init__(self, vocab_size, key_size, query_size, value_size,\r\n",
        "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\r\n",
        "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\r\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\r\n",
        "        self.num_hiddens = num_hiddens\r\n",
        "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\r\n",
        "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\r\n",
        "        self.blks = nn.Sequential()\r\n",
        "        for i in range(num_layers):\r\n",
        "            self.blks.add_module(\r\n",
        "                \"block\" + str(i),\r\n",
        "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\r\n",
        "                             norm_shape, ffn_num_input, ffn_num_hiddens,\r\n",
        "                             num_heads, dropout, use_bias))\r\n",
        "\r\n",
        "    def forward(self, X, valid_lens, *args):\r\n",
        "        # Since positional encoding values are between -1 and 1, the embedding\r\n",
        "        # values are multiplied by the square root of the embedding dimension\r\n",
        "        # to rescale before they are summed up\r\n",
        "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\r\n",
        "        self.attention_weights = [None] * len(self.blks)\r\n",
        "        for i, blk in enumerate(self.blks):\r\n",
        "            X = blk(X, valid_lens)\r\n",
        "            self.attention_weights[\r\n",
        "                i] = blk.attention.attention.attention_weights\r\n",
        "        return X\r\n",
        "\r\n",
        "\r\n",
        "# Alias defined in config.ini\r\n",
        "\r\n",
        "\r\n",
        "ones = torch.ones\r\n",
        "zeros = torch.zeros\r\n",
        "tensor = torch.tensor\r\n",
        "arange = torch.arange\r\n",
        "meshgrid = torch.meshgrid\r\n",
        "sin = torch.sin\r\n",
        "sinh = torch.sinh\r\n",
        "cos = torch.cos\r\n",
        "cosh = torch.cosh\r\n",
        "tanh = torch.tanh\r\n",
        "linspace = torch.linspace\r\n",
        "exp = torch.exp\r\n",
        "log = torch.log\r\n",
        "normal = torch.normal\r\n",
        "rand = torch.rand\r\n",
        "matmul = torch.matmul\r\n",
        "int32 = torch.int32\r\n",
        "float32 = torch.float32\r\n",
        "concat = torch.cat\r\n",
        "stack = torch.stack\r\n",
        "abs = torch.abs\r\n",
        "eye = torch.eye\r\n",
        "numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\r\n",
        "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\r\n",
        "reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\r\n",
        "to = lambda x, *args, **kwargs: x.to(*args, **kwargs)\r\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\r\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\r\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\r\n",
        "transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8sozVv5lEhm"
      },
      "source": [
        "def dropout(X,drop_prob):\r\n",
        "    X = X.float()\r\n",
        "    assert 0<=drop_prob<=1\r\n",
        "    keep_prob = 1-drop_prob\r\n",
        "\r\n",
        "    # 这种情况下把全部元素都丢弃\r\n",
        "    if keep_prob ==0:\r\n",
        "        return torch.zeros_like(X)\r\n",
        "    mask = (torch.rand(X.shape)<keep_prob).float()\r\n",
        "\r\n",
        "    return mask*X/keep_prob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAx_1QHjnKM3",
        "outputId": "d876c64a-8b28-4bcb-ddcb-e70721af43f0"
      },
      "source": [
        "X = torch.arange(16).view(2,8)\r\n",
        "dropout(X,0)\r\n",
        "dropout(X,0.5)\r\n",
        "dropout(X,1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1maNtIrnXE_"
      },
      "source": [
        "### 2.1 定义模型参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DG-HQ5nbT9"
      },
      "source": [
        "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\r\n",
        "\r\n",
        "W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)\r\n",
        "b1 = torch.zeros(num_hiddens1, requires_grad=True)\r\n",
        "W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)\r\n",
        "b2 = torch.zeros(num_hiddens2, requires_grad=True)\r\n",
        "W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)\r\n",
        "b3 = torch.zeros(num_outputs, requires_grad=True)\r\n",
        "\r\n",
        "params = [W1, b1, W2, b2, W3, b3]\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErzOROslpr8s"
      },
      "source": [
        "### 2.2 定义模型\r\n",
        "下面定义的模型将全连接层和激活函数ReLU串起来，并对每个激活函数的输出使用丢弃法。我们可以分别设置各个层的丢弃概率。通常的建议是把靠近输入层的丢弃概率设得小一点。在这个实验中，我们把第一个隐藏层的丢弃概率设为0.2，把第二个隐藏层的丢弃概率设为0.5。我们可以通过参数is_training来判断运行模式为训练还是测试，并只需在训练模式下使用丢弃法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5tQH1hFpuBE"
      },
      "source": [
        "drop_prob1,drop_prob2 = 0.2,0.5\r\n",
        "\r\n",
        "def net(X,is_training=True):\r\n",
        "    X = X.view(-1,num_inputs)\r\n",
        "    H1 = (torch.matmul(X,W1)+b1).relu()\r\n",
        "    if is_training:\r\n",
        "        H1 = dropout(H1,drop_prob1)\r\n",
        "    H2 = (torch.matmul(H1,W2)+b2).relu()\r\n",
        "    if is_training:\r\n",
        "        H2 = dropout(H2,drop_prob2)\r\n",
        "    return torch.matmul(H2,W3)+b3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzP6W9Cfqmw-"
      },
      "source": [
        "我们在对模型评估的时候不应该进行丢弃，所以我们修改一下d2lzh_pytorch中的evaluate_accuracy函数:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGWbN5zrqopg"
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\r\n",
        "    acc_sum, n = 0.0, 0\r\n",
        "    for X, y in data_iter:\r\n",
        "        if isinstance(net, torch.nn.Module):\r\n",
        "            net.eval() # 评估模式, 这会关闭dropout\r\n",
        "            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\r\n",
        "            net.train() # 改回训练模式\r\n",
        "        else: # 自定义的模型\r\n",
        "            if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\r\n",
        "                # 将is_training设置成False\r\n",
        "                acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \r\n",
        "            else:\r\n",
        "                acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \r\n",
        "        n += y.shape[0]\r\n",
        "    return acc_sum / n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9EouOx7qsLj"
      },
      "source": [
        "### 2.3 训练和测试模型\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgADNzVtr-O8"
      },
      "source": [
        "def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        train_l_sum,train_acc_sum,n=0.0,0.0,0\r\n",
        "        for X,y in train_iter:\r\n",
        "            y_hat=net(X)\r\n",
        "            l = loss(y_hat,y).sum()\r\n",
        "\r\n",
        "            # 梯度清零\r\n",
        "            if optimizer is not None:\r\n",
        "                optimizer.zero_grad()\r\n",
        "            elif params is not None and params[0].grad is not None:\r\n",
        "                for param in params:\r\n",
        "                    param.grad.data.zero_()\r\n",
        "            \r\n",
        "            l.backward()\r\n",
        "            if optimizer is None:\r\n",
        "                sgd(params,lr,batch_size)\r\n",
        "            else:\r\n",
        "                optimizer.step()\r\n",
        "            \r\n",
        "            train_l_sum += l.item()\r\n",
        "            train_acc_sum += (y_hat.argmax(dim=1)==y).sum().item()\r\n",
        "            n += y.shape[0]\r\n",
        "        test_acc = evaluate_accuracy(test_iter,net)\r\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\r\n",
        "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg3p8jbrqxfp",
        "outputId": "1212b4d5-b258-4983-8399-82c6023f800f"
      },
      "source": [
        "num_epochs, lr, batch_size = 5, 100.0, 256\r\n",
        "loss = torch.nn.CrossEntropyLoss()\r\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size)\r\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.0019, train acc 0.822, test acc 0.819\n",
            "epoch 2, loss 0.0017, train acc 0.841, test acc 0.782\n",
            "epoch 3, loss 0.0016, train acc 0.850, test acc 0.828\n",
            "epoch 4, loss 0.0015, train acc 0.858, test acc 0.849\n",
            "epoch 5, loss 0.0015, train acc 0.862, test acc 0.859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twd2HuyzsrjJ"
      },
      "source": [
        "## 3. 简洁实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCxJ-l2fuHrc"
      },
      "source": [
        "在PyTorch中，我们只需要在全连接层后添加Dropout层并指定丢弃概率。在训练模型时，Dropout层将以指定的丢弃概率随机丢弃上一层的输出元素；在测试模型时（即model.eval()后），Dropout层并不发挥作用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI19t4z0uoo_"
      },
      "source": [
        "class FlattenLayer(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(FlattenLayer, self).__init__()\r\n",
        "    def forward(self, x): # x shape: (batch, *, *, ...)\r\n",
        "        return x.view(x.shape[0], -1)\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztXiLnn8sunr"
      },
      "source": [
        "net = nn.Sequential(\r\n",
        "        FlattenLayer(),\r\n",
        "        nn.Linear(num_inputs, num_hiddens1),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Dropout(drop_prob1),\r\n",
        "        nn.Linear(num_hiddens1, num_hiddens2), \r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Dropout(drop_prob2),\r\n",
        "        nn.Linear(num_hiddens2, 10)\r\n",
        "        )\r\n",
        "\r\n",
        "for param in net.parameters():\r\n",
        "    nn.init.normal_(param, mean=0, std=0.01)\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgU2cWzPusSU",
        "outputId": "1a28a7cc-4d24-419c-bc01-295049f416cd"
      },
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(),lr=0.5)\r\n",
        "train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,None,None,optimizer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.0044, train acc 0.567, test acc 0.725\n",
            "epoch 2, loss 0.0022, train acc 0.788, test acc 0.799\n",
            "epoch 3, loss 0.0019, train acc 0.824, test acc 0.801\n",
            "epoch 4, loss 0.0017, train acc 0.840, test acc 0.776\n",
            "epoch 5, loss 0.0017, train acc 0.845, test acc 0.820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldIXezInu-VJ"
      },
      "source": [
        "我们可以通过使用丢弃法应对过拟合。\r\n",
        "\r\n",
        "\r\n",
        "丢弃法只在训练模型时使用。"
      ]
    }
  ]
}
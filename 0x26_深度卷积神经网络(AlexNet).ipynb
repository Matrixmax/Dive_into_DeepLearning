{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0x26_深度卷积神经网络(AlexNet).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtj6HDXW4O8DhIf1KT0DqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4eb41d5f625d4c8c8f5d172ddb19fda9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3994679f06b641d09a6e8e6a322f6dbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f35cd3628c44ffaa1a92a66866ade7b",
              "IPY_MODEL_617f37e30ea84c5d9cd57082539e7360"
            ]
          }
        },
        "3994679f06b641d09a6e8e6a322f6dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f35cd3628c44ffaa1a92a66866ade7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9ad77fb346348d69f2f1abba084b266",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_808ffb7935534233becb9c7e94846893"
          }
        },
        "617f37e30ea84c5d9cd57082539e7360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d13e0cc7846466d9b21f022682459ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 4703144.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac783a184d0042abbf33852901898c5f"
          }
        },
        "e9ad77fb346348d69f2f1abba084b266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "808ffb7935534233becb9c7e94846893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d13e0cc7846466d9b21f022682459ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac783a184d0042abbf33852901898c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da1a3c490f74488493299b5a3b54649f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8518a1e2572492a8e33108dbe8de9b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee6eea83dde945f0b7d8e8ff4198b3fe",
              "IPY_MODEL_0367a080bf864717a11f603c6c50aa69"
            ]
          }
        },
        "c8518a1e2572492a8e33108dbe8de9b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee6eea83dde945f0b7d8e8ff4198b3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e8f0172290a40148261e1b205372be7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af509a94b3324dbaa164ae8f034f0d57"
          }
        },
        "0367a080bf864717a11f603c6c50aa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ac7c06a7a84481a9094b09b0de4448c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 104480.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_314108679d124a75a8078ec4d5b79019"
          }
        },
        "2e8f0172290a40148261e1b205372be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af509a94b3324dbaa164ae8f034f0d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ac7c06a7a84481a9094b09b0de4448c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "314108679d124a75a8078ec4d5b79019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "289418baa87a4d9bb85b2e530245acc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_90ddcdaf081b4fd8b342476bdd8cda06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8eccad20ce11449a956952d8c417b45f",
              "IPY_MODEL_9e2a2ec770054c32adc238cf8935c733"
            ]
          }
        },
        "90ddcdaf081b4fd8b342476bdd8cda06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eccad20ce11449a956952d8c417b45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_22bf3cffde1c472098d7f0c77c5c38ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0ecee9467e84070b275696e79008a34"
          }
        },
        "9e2a2ec770054c32adc238cf8935c733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc1448c158b743da99decc08ef235213",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:17&lt;00:00, 901556.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a3047300508447bbc172ae06d47e849"
          }
        },
        "22bf3cffde1c472098d7f0c77c5c38ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0ecee9467e84070b275696e79008a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc1448c158b743da99decc08ef235213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a3047300508447bbc172ae06d47e849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a018591ca8a04884a2dfa98e61bc004b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_119bc2da7f3e4bc785a08dd2affbc3ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7a14b74f66c4e5db10a3849dd7c60f6",
              "IPY_MODEL_deca761bbb3c47a08ff6cd6f19542fbf"
            ]
          }
        },
        "119bc2da7f3e4bc785a08dd2affbc3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7a14b74f66c4e5db10a3849dd7c60f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6eeb036ea69145a38b04a9df7cec8a94",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06403622ee764938849edde472a22ba1"
          }
        },
        "deca761bbb3c47a08ff6cd6f19542fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9de8f34840dd428d9f119b8b0fdffa2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/5148 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e6dbc9a2c464185ba79f34442d27d99"
          }
        },
        "6eeb036ea69145a38b04a9df7cec8a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06403622ee764938849edde472a22ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9de8f34840dd428d9f119b8b0fdffa2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e6dbc9a2c464185ba79f34442d27d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrixmax/Dive_into_DeepLearning/blob/main/0x26_%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL5w0rkvCqK2"
      },
      "source": [
        "我们在上一节看到，神经网络可以直接基于图像的原始像素进行分类。这种称为端到端（end-to-end）的方法节省了很多中间步骤。然而，在很长一段时间里更流行的是研究者通过勤劳与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：\r\n",
        "1. 获取图像数据集；\r\n",
        "2. 使用已有的特征提取函数生成图像的特征；\r\n",
        "3. 使用机器学习模型对图像的特征分类。\r\n",
        "\r\n",
        "当时认为的机器学习部分仅限最后这一步。如果那时候跟机器学习研究者交谈，他们会认为机器学习既重要又优美。优雅的定理证明了许多分类器的性质。机器学习领域生机勃勃、严谨而且极其有用。然而，如果跟计算机视觉研究者交谈，则是另外一幅景象。他们会告诉你图像识别里“不可告人”的现实是：计算机视觉流程中真正重要的是数据和特征。也就是说，使用较干净的数据集和较有效的特征甚至比机器学习模型的选择对图像分类结果的影响更大。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x61hwofmC0jn"
      },
      "source": [
        "## 1.学习特征表示\r\n",
        "\r\n",
        "我们已经提到，在相当长的时间里，特征都是基于各式各样手工设计的函数从数据中提取的。事实上，不少研究者通过提出新的特征提取函数不断改进图像分类结果。这一度为计算机视觉的发展做出了重要贡献。\r\n",
        "\r\n",
        "然而，另一些研究者则持异议。他们认为特征本身也应该由学习得来。他们还相信，为了表征足够复杂的输入，特征本身应该分级表示。持这一想法的研究者相信，多层神经网络可能可以学得数据的多级表征，并逐级表示越来越抽象的概念或模式。以图像分类为例，并回忆5.1节（二维卷积层）中物体边缘检测的例子。在多层神经网络中，图像的第一级的表示可以是在特定的位置和⻆度是否出现边缘；而第二级的表示说不定能够将这些边缘组合出有趣的模式，如花纹；在第三级的表示中，也许上一级的花纹能进一步汇合成对应物体特定部位的模式。这样逐级表示下去，最终，模型能够较容易根据最后一级的表示完成分类任务。需要强调的是，输入的逐级表示由多层模型中的参数决定，而这些参数都是学出来的。\r\n",
        "\r\n",
        "尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些野心都未能实现。这其中有诸多因素值得我们一一分析。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTgv1s0EGRJ"
      },
      "source": [
        "### 3.1 缺失要素1：数据\r\n",
        "包含许多特征的深度模型需要大量的有标签的数据才能表现得比其他经典方法更好。限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。特别是，2009年诞生的ImageNet数据集包含了1,000大类物体，每类有多达数千张不同的图像。这一规模是当时其他公开数据集无法与之相提并论的。ImageNet数据集同时推动计算机视觉和机器学习研究进入新的阶段，使此前的传统方法不再有优势。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4e6aK4iFVLK"
      },
      "source": [
        "### 3.2 缺失要素2：硬件\r\n",
        "深度学习对计算资源要求很高。早期的硬件计算能力有限，这使训练较复杂的神经网络变得很困难。然而，通用GPU的到来改变了这一格局。很久以来，GPU都是为图像处理和计算机游戏设计的，尤其是针对大吞吐量的矩阵和向量乘法从而服务于基本的图形变换。值得庆幸的是，这其中的数学表达与深度网络中的卷积层的表达类似。通用GPU这个概念在2001年开始兴起，涌现出诸如OpenCL和CUDA之类的编程框架。这使得GPU也在2010年前后开始被机器学习社区使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buBb9he-GJ5F"
      },
      "source": [
        "## 2. AlexNet\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVv_z9ONGOym"
      },
      "source": [
        "AlexNet与LeNet的设计理念非常相似，但也有显著的区别。\r\n",
        "\r\n",
        "第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。下面我们来详细描述这些层的设计。\r\n",
        "\r\n",
        "AlexNet第一层中的卷积窗口形状是11×1111×11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×55×5，之后全采用3×33×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×33×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。\r\n",
        "\r\n",
        "紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。\r\n",
        "\r\n",
        "第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。\r\n",
        "\r\n",
        "第三，AlexNet通过丢弃法（参见3.13节）来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。\r\n",
        "\r\n",
        "第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。我们将在后面的9.1节（图像增广）详细介绍这种方法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WswZrhD84yoS"
      },
      "source": [
        "import collections\r\n",
        "import math\r\n",
        "import os\r\n",
        "import random\r\n",
        "import sys\r\n",
        "import tarfile\r\n",
        "import time\r\n",
        "import json\r\n",
        "import zipfile\r\n",
        "from tqdm import tqdm\r\n",
        "from PIL import Image\r\n",
        "from collections import namedtuple\r\n",
        "\r\n",
        "from IPython import display\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchtext\r\n",
        "import torchtext.vocab as Vocab\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\r\n",
        "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\r\n",
        "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\r\n",
        "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\r\n",
        "\r\n",
        "\r\n",
        "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\r\n",
        "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\r\n",
        "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\r\n",
        "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\r\n",
        "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\r\n",
        "                [0, 64, 128]]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ###################### 3.2 ############################\r\n",
        "def set_figsize(figsize=(3.5, 2.5)):\r\n",
        "    use_svg_display()\r\n",
        "    # 设置图的尺寸\r\n",
        "    plt.rcParams['figure.figsize'] = figsize\r\n",
        "\r\n",
        "def use_svg_display():\r\n",
        "    \"\"\"Use svg format to display plot in jupyter\"\"\"\r\n",
        "    display.set_matplotlib_formats('svg')\r\n",
        "\r\n",
        "def data_iter(batch_size, features, labels):\r\n",
        "    num_examples = len(features)\r\n",
        "    indices = list(range(num_examples))\r\n",
        "    random.shuffle(indices)  # 样本的读取顺序是随机的\r\n",
        "    for i in range(0, num_examples, batch_size):\r\n",
        "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch\r\n",
        "        yield  features.index_select(0, j), labels.index_select(0, j) \r\n",
        "\r\n",
        "def linreg(X, w, b):\r\n",
        "    return torch.mm(X, w) + b\r\n",
        "\r\n",
        "def squared_loss(y_hat, y): \r\n",
        "    # 注意这里返回的是向量, 另外, pytorch里的MSELoss并没有除以 2\r\n",
        "    return ((y_hat - y.view(y_hat.size())) ** 2) / 2\r\n",
        "\r\n",
        "def sgd(params, lr, batch_size):\r\n",
        "    # 为了和原书保持一致，这里除以了batch_size，但是应该是不用除的，因为一般用PyTorch计算loss时就默认已经\r\n",
        "    # 沿batch维求了平均了。\r\n",
        "    for param in params:\r\n",
        "        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ######################3##### 3.5 #############################\r\n",
        "def get_fashion_mnist_labels(labels):\r\n",
        "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\r\n",
        "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\r\n",
        "    return [text_labels[int(i)] for i in labels]\r\n",
        "\r\n",
        "def show_fashion_mnist(images, labels):\r\n",
        "    use_svg_display()\r\n",
        "    # 这里的_表示我们忽略（不使用）的变量\r\n",
        "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\r\n",
        "    for f, img, lbl in zip(figs, images, labels):\r\n",
        "        f.imshow(img.view((28, 28)).numpy())\r\n",
        "        f.set_title(lbl)\r\n",
        "        f.axes.get_xaxis().set_visible(False)\r\n",
        "        f.axes.get_yaxis().set_visible(False)\r\n",
        "    # plt.show()\r\n",
        "\r\n",
        "# 5.6 修改\r\n",
        "# def load_data_fashion_mnist(batch_size, root='~/Datasets/FashionMNIST'):\r\n",
        "#     \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\r\n",
        "#     transform = transforms.ToTensor()\r\n",
        "#     mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\r\n",
        "#     mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\r\n",
        "#     if sys.platform.startswith('win'):\r\n",
        "#         num_workers = 0  # 0表示不用额外的进程来加速读取数据\r\n",
        "#     else:\r\n",
        "#         num_workers = 4\r\n",
        "#     train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\r\n",
        "#     test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\r\n",
        "\r\n",
        "#     return train_iter, test_iter\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 3.6  ###############################\r\n",
        "# (3.13节修改)\r\n",
        "# def evaluate_accuracy(data_iter, net):\r\n",
        "#     acc_sum, n = 0.0, 0\r\n",
        "#     for X, y in data_iter:\r\n",
        "#         acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\r\n",
        "#         n += y.shape[0]\r\n",
        "#     return acc_sum / n\r\n",
        "\r\n",
        "\r\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\r\n",
        "              params=None, lr=None, optimizer=None):\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\r\n",
        "        for X, y in train_iter:\r\n",
        "            y_hat = net(X)\r\n",
        "            l = loss(y_hat, y).sum()\r\n",
        "            \r\n",
        "            # 梯度清零\r\n",
        "            if optimizer is not None:\r\n",
        "                optimizer.zero_grad()\r\n",
        "            elif params is not None and params[0].grad is not None:\r\n",
        "                for param in params:\r\n",
        "                    param.grad.data.zero_()\r\n",
        "            \r\n",
        "            l.backward()\r\n",
        "            if optimizer is None:\r\n",
        "                sgd(params, lr, batch_size)\r\n",
        "            else:\r\n",
        "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\r\n",
        "            \r\n",
        "            \r\n",
        "            train_l_sum += l.item()\r\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\r\n",
        "            n += y.shape[0]\r\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\r\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\r\n",
        "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 3.7 #####################################3\r\n",
        "class FlattenLayer(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(FlattenLayer, self).__init__()\r\n",
        "    def forward(self, x): # x shape: (batch, *, *, ...)\r\n",
        "        return x.view(x.shape[0], -1)\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 3.11 ###############################\r\n",
        "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\r\n",
        "             legend=None, figsize=(3.5, 2.5)):\r\n",
        "    set_figsize(figsize)\r\n",
        "    plt.xlabel(x_label)\r\n",
        "    plt.ylabel(y_label)\r\n",
        "    plt.semilogy(x_vals, y_vals)\r\n",
        "    if x2_vals and y2_vals:\r\n",
        "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\r\n",
        "        plt.legend(legend)\r\n",
        "    # plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ############################# 3.13 ##############################\r\n",
        "# 5.5 修改\r\n",
        "# def evaluate_accuracy(data_iter, net):\r\n",
        "#     acc_sum, n = 0.0, 0\r\n",
        "#     for X, y in data_iter:\r\n",
        "#         if isinstance(net, torch.nn.Module):\r\n",
        "#             net.eval() # 评估模式, 这会关闭dropout\r\n",
        "#             acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\r\n",
        "#             net.train() # 改回训练模式\r\n",
        "#         else: # 自定义的模型\r\n",
        "#             if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\r\n",
        "#                 # 将is_training设置成False\r\n",
        "#                 acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \r\n",
        "#             else:\r\n",
        "#                 acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \r\n",
        "#         n += y.shape[0]\r\n",
        "#     return acc_sum / n\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 5.1 #########################\r\n",
        "def corr2d(X, K):  \r\n",
        "    h, w = K.shape\r\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\r\n",
        "    for i in range(Y.shape[0]):\r\n",
        "        for j in range(Y.shape[1]):\r\n",
        "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\r\n",
        "    return Y\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ############################ 5.5 #########################\r\n",
        "def evaluate_accuracy(data_iter, net, device=None):\r\n",
        "    if device is None and isinstance(net, torch.nn.Module):\r\n",
        "        # 如果没指定device就使用net的device\r\n",
        "        device = list(net.parameters())[0].device \r\n",
        "    acc_sum, n = 0.0, 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for X, y in data_iter:\r\n",
        "            if isinstance(net, torch.nn.Module):\r\n",
        "                net.eval() # 评估模式, 这会关闭dropout\r\n",
        "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\r\n",
        "                net.train() # 改回训练模式\r\n",
        "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\r\n",
        "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\r\n",
        "                    # 将is_training设置成False\r\n",
        "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \r\n",
        "                else:\r\n",
        "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \r\n",
        "            n += y.shape[0]\r\n",
        "    return acc_sum / n\r\n",
        "\r\n",
        "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\r\n",
        "    net = net.to(device)\r\n",
        "    print(\"training on \", device)\r\n",
        "    loss = torch.nn.CrossEntropyLoss()\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\r\n",
        "        for X, y in train_iter:\r\n",
        "            X = X.to(device)\r\n",
        "            y = y.to(device)\r\n",
        "            y_hat = net(X)\r\n",
        "            l = loss(y_hat, y)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            optimizer.step()\r\n",
        "            train_l_sum += l.cpu().item()\r\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\r\n",
        "            n += y.shape[0]\r\n",
        "            batch_count += 1\r\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\r\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\r\n",
        "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################## 5.6 #########################3\r\n",
        "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\r\n",
        "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\r\n",
        "    trans = []\r\n",
        "    if resize:\r\n",
        "        trans.append(torchvision.transforms.Resize(size=resize))\r\n",
        "    trans.append(torchvision.transforms.ToTensor())\r\n",
        "    \r\n",
        "    transform = torchvision.transforms.Compose(trans)\r\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\r\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\r\n",
        "    if sys.platform.startswith('win'):\r\n",
        "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\r\n",
        "    else:\r\n",
        "        num_workers = 4\r\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\r\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\r\n",
        "\r\n",
        "    return train_iter, test_iter\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "############################# 5.8 ##############################\r\n",
        "class GlobalAvgPool2d(nn.Module):\r\n",
        "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\r\n",
        "    def __init__(self):\r\n",
        "        super(GlobalAvgPool2d, self).__init__()\r\n",
        "    def forward(self, x):\r\n",
        "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 5.11 ################################\r\n",
        "class Residual(nn.Module): \r\n",
        "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\r\n",
        "        super(Residual, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\r\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\r\n",
        "        if use_1x1conv:\r\n",
        "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\r\n",
        "        else:\r\n",
        "            self.conv3 = None\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\r\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\r\n",
        "        Y = self.bn2(self.conv2(Y))\r\n",
        "        if self.conv3:\r\n",
        "            X = self.conv3(X)\r\n",
        "        return F.relu(Y + X)\r\n",
        "\r\n",
        "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\r\n",
        "    if first_block:\r\n",
        "        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\r\n",
        "    blk = []\r\n",
        "    for i in range(num_residuals):\r\n",
        "        if i == 0 and not first_block:\r\n",
        "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\r\n",
        "        else:\r\n",
        "            blk.append(Residual(out_channels, out_channels))\r\n",
        "    return nn.Sequential(*blk)\r\n",
        "    \r\n",
        "def resnet18(output=10, in_channels=3):\r\n",
        "    net = nn.Sequential(\r\n",
        "        nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\r\n",
        "        nn.BatchNorm2d(64), \r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\r\n",
        "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\r\n",
        "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\r\n",
        "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\r\n",
        "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\r\n",
        "    net.add_module(\"global_avg_pool\", GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\r\n",
        "    net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(512, output))) \r\n",
        "    return net\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ############################## 6.3 ##################################3\r\n",
        "def load_data_jay_lyrics():\r\n",
        "    \"\"\"加载周杰伦歌词数据集\"\"\"\r\n",
        "    with zipfile.ZipFile('../../data/jaychou_lyrics.txt.zip') as zin:\r\n",
        "        with zin.open('jaychou_lyrics.txt') as f:\r\n",
        "            corpus_chars = f.read().decode('utf-8')\r\n",
        "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\r\n",
        "    corpus_chars = corpus_chars[0:10000]\r\n",
        "    idx_to_char = list(set(corpus_chars))\r\n",
        "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\r\n",
        "    vocab_size = len(char_to_idx)\r\n",
        "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\r\n",
        "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\r\n",
        "\r\n",
        "def data_iter_random(corpus_indices, batch_size, num_steps, device=None):\r\n",
        "    # 减1是因为输出的索引x是相应输入的索引y加1\r\n",
        "    num_examples = (len(corpus_indices) - 1) // num_steps\r\n",
        "    epoch_size = num_examples // batch_size\r\n",
        "    example_indices = list(range(num_examples))\r\n",
        "    random.shuffle(example_indices)\r\n",
        "\r\n",
        "    # 返回从pos开始的长为num_steps的序列\r\n",
        "    def _data(pos):\r\n",
        "        return corpus_indices[pos: pos + num_steps]\r\n",
        "    if device is None:\r\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "    \r\n",
        "    for i in range(epoch_size):\r\n",
        "        # 每次读取batch_size个随机样本\r\n",
        "        i = i * batch_size\r\n",
        "        batch_indices = example_indices[i: i + batch_size]\r\n",
        "        X = [_data(j * num_steps) for j in batch_indices]\r\n",
        "        Y = [_data(j * num_steps + 1) for j in batch_indices]\r\n",
        "        yield torch.tensor(X, dtype=torch.float32, device=device), torch.tensor(Y, dtype=torch.float32, device=device)\r\n",
        "\r\n",
        "def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\r\n",
        "    if device is None:\r\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\r\n",
        "    data_len = len(corpus_indices)\r\n",
        "    batch_len = data_len // batch_size\r\n",
        "    indices = corpus_indices[0: batch_size*batch_len].view(batch_size, batch_len)\r\n",
        "    epoch_size = (batch_len - 1) // num_steps\r\n",
        "    for i in range(epoch_size):\r\n",
        "        i = i * num_steps\r\n",
        "        X = indices[:, i: i + num_steps]\r\n",
        "        Y = indices[:, i + 1: i + num_steps + 1]\r\n",
        "        yield X, Y\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ###################################### 6.4 ######################################\r\n",
        "def one_hot(x, n_class, dtype=torch.float32): \r\n",
        "    # X shape: (batch), output shape: (batch, n_class)\r\n",
        "    x = x.long()\r\n",
        "    res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\r\n",
        "    res.scatter_(1, x.view(-1, 1), 1)\r\n",
        "    return res\r\n",
        "\r\n",
        "def to_onehot(X, n_class):  \r\n",
        "    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\r\n",
        "    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\r\n",
        "\r\n",
        "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\r\n",
        "                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\r\n",
        "    state = init_rnn_state(1, num_hiddens, device)\r\n",
        "    output = [char_to_idx[prefix[0]]]\r\n",
        "    for t in range(num_chars + len(prefix) - 1):\r\n",
        "        # 将上一时间步的输出作为当前时间步的输入\r\n",
        "        X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\r\n",
        "        # 计算输出和更新隐藏状态\r\n",
        "        (Y, state) = rnn(X, state, params)\r\n",
        "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\r\n",
        "        if t < len(prefix) - 1:\r\n",
        "            output.append(char_to_idx[prefix[t + 1]])\r\n",
        "        else:\r\n",
        "            output.append(int(Y[0].argmax(dim=1).item()))\r\n",
        "    return ''.join([idx_to_char[i] for i in output])\r\n",
        "\r\n",
        "def grad_clipping(params, theta, device):\r\n",
        "    norm = torch.tensor([0.0], device=device)\r\n",
        "    for param in params:\r\n",
        "        norm += (param.grad.data ** 2).sum()\r\n",
        "    norm = norm.sqrt().item()\r\n",
        "    if norm > theta:\r\n",
        "        for param in params:\r\n",
        "            param.grad.data *= (theta / norm)\r\n",
        "\r\n",
        "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\r\n",
        "                          vocab_size, device, corpus_indices, idx_to_char,\r\n",
        "                          char_to_idx, is_random_iter, num_epochs, num_steps,\r\n",
        "                          lr, clipping_theta, batch_size, pred_period,\r\n",
        "                          pred_len, prefixes):\r\n",
        "    if is_random_iter:\r\n",
        "        data_iter_fn = data_iter_random\r\n",
        "    else:\r\n",
        "        data_iter_fn = data_iter_consecutive\r\n",
        "    params = get_params()\r\n",
        "    loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\r\n",
        "            state = init_rnn_state(batch_size, num_hiddens, device)\r\n",
        "        l_sum, n, start = 0.0, 0, time.time()\r\n",
        "        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)\r\n",
        "        for X, Y in data_iter:\r\n",
        "            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\r\n",
        "                state = init_rnn_state(batch_size, num_hiddens, device)\r\n",
        "            else: \r\n",
        "            # 否则需要使用detach函数从计算图分离隐藏状态, 这是为了\r\n",
        "            # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\r\n",
        "                for s in state:\r\n",
        "                    s.detach_()\r\n",
        "            \r\n",
        "            inputs = to_onehot(X, vocab_size)\r\n",
        "            # outputs有num_steps个形状为(batch_size, vocab_size)的矩阵\r\n",
        "            (outputs, state) = rnn(inputs, state, params)\r\n",
        "            # 拼接之后形状为(num_steps * batch_size, vocab_size)\r\n",
        "            outputs = torch.cat(outputs, dim=0)\r\n",
        "            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\r\n",
        "            # batch * num_steps 的向量，这样跟输出的行一一对应\r\n",
        "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\r\n",
        "            # 使用交叉熵损失计算平均分类误差\r\n",
        "            l = loss(outputs, y.long())\r\n",
        "            \r\n",
        "            # 梯度清0\r\n",
        "            if params[0].grad is not None:\r\n",
        "                for param in params:\r\n",
        "                    param.grad.data.zero_()\r\n",
        "            l.backward()\r\n",
        "            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\r\n",
        "            sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\r\n",
        "            l_sum += l.item() * y.shape[0]\r\n",
        "            n += y.shape[0]\r\n",
        "\r\n",
        "        if (epoch + 1) % pred_period == 0:\r\n",
        "            print('epoch %d, perplexity %f, time %.2f sec' % (\r\n",
        "                epoch + 1, math.exp(l_sum / n), time.time() - start))\r\n",
        "            for prefix in prefixes:\r\n",
        "                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\r\n",
        "                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))\r\n",
        "\r\n",
        "                \r\n",
        "                \r\n",
        "                \r\n",
        "# ################################### 6.5 ################################################\r\n",
        "class RNNModel(nn.Module):\r\n",
        "    def __init__(self, rnn_layer, vocab_size):\r\n",
        "        super(RNNModel, self).__init__()\r\n",
        "        self.rnn = rnn_layer\r\n",
        "        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.dense = nn.Linear(self.hidden_size, vocab_size)\r\n",
        "        self.state = None\r\n",
        "\r\n",
        "    def forward(self, inputs, state): # inputs: (batch, seq_len)\r\n",
        "        # 获取one-hot向量表示\r\n",
        "        X = to_onehot(inputs, self.vocab_size) # X是个list\r\n",
        "        Y, self.state = self.rnn(torch.stack(X), state)\r\n",
        "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\r\n",
        "        # 形状为(num_steps * batch_size, vocab_size)\r\n",
        "        output = self.dense(Y.view(-1, Y.shape[-1]))\r\n",
        "        return output, self.state\r\n",
        "\r\n",
        "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\r\n",
        "                      char_to_idx):\r\n",
        "    state = None\r\n",
        "    output = [char_to_idx[prefix[0]]] # output会记录prefix加上输出\r\n",
        "    for t in range(num_chars + len(prefix) - 1):\r\n",
        "        X = torch.tensor([output[-1]], device=device).view(1, 1)\r\n",
        "        if state is not None:\r\n",
        "            if isinstance(state, tuple): # LSTM, state:(h, c)  \r\n",
        "                state = (state[0].to(device), state[1].to(device))\r\n",
        "            else:   \r\n",
        "                state = state.to(device)\r\n",
        "            \r\n",
        "        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\r\n",
        "        if t < len(prefix) - 1:\r\n",
        "            output.append(char_to_idx[prefix[t + 1]])\r\n",
        "        else:\r\n",
        "            output.append(int(Y.argmax(dim=1).item()))\r\n",
        "    return ''.join([idx_to_char[i] for i in output])\r\n",
        "\r\n",
        "def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\r\n",
        "                                corpus_indices, idx_to_char, char_to_idx,\r\n",
        "                                num_epochs, num_steps, lr, clipping_theta,\r\n",
        "                                batch_size, pred_period, pred_len, prefixes):\r\n",
        "    loss = nn.CrossEntropyLoss()\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "    model.to(device)\r\n",
        "    state = None\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        l_sum, n, start = 0.0, 0, time.time()\r\n",
        "        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\r\n",
        "        for X, Y in data_iter:\r\n",
        "            if state is not None:\r\n",
        "                # 使用detach函数从计算图分离隐藏状态, 这是为了\r\n",
        "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\r\n",
        "                if isinstance (state, tuple): # LSTM, state:(h, c)  \r\n",
        "                    state = (state[0].detach(), state[1].detach())\r\n",
        "                else:   \r\n",
        "                    state = state.detach()\r\n",
        "    \r\n",
        "            (output, state) = model(X, state) # output: 形状为(num_steps * batch_size, vocab_size)\r\n",
        "            \r\n",
        "            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\r\n",
        "            # batch * num_steps 的向量，这样跟输出的行一一对应\r\n",
        "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\r\n",
        "            l = loss(output, y.long())\r\n",
        "            \r\n",
        "            optimizer.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            # 梯度裁剪\r\n",
        "            grad_clipping(model.parameters(), clipping_theta, device)\r\n",
        "            optimizer.step()\r\n",
        "            l_sum += l.item() * y.shape[0]\r\n",
        "            n += y.shape[0]\r\n",
        "        \r\n",
        "        try:\r\n",
        "            perplexity = math.exp(l_sum / n)\r\n",
        "        except OverflowError:\r\n",
        "            perplexity = float('inf')\r\n",
        "        if (epoch + 1) % pred_period == 0:\r\n",
        "            print('epoch %d, perplexity %f, time %.2f sec' % (\r\n",
        "                epoch + 1, perplexity, time.time() - start))\r\n",
        "            for prefix in prefixes:\r\n",
        "                print(' -', predict_rnn_pytorch(\r\n",
        "                    prefix, pred_len, model, vocab_size, device, idx_to_char,\r\n",
        "                    char_to_idx))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ######################################## 7.2 ###############################################\r\n",
        "def train_2d(trainer):  \r\n",
        "    x1, x2, s1, s2 = -5, -2, 0, 0  # s1和s2是自变量状态，本章后续几节会使用\r\n",
        "    results = [(x1, x2)]\r\n",
        "    for i in range(20):\r\n",
        "        x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\r\n",
        "        results.append((x1, x2))\r\n",
        "    print('epoch %d, x1 %f, x2 %f' % (i + 1, x1, x2))\r\n",
        "    return results\r\n",
        "\r\n",
        "def show_trace_2d(f, results):  \r\n",
        "    plt.plot(*zip(*results), '-o', color='#ff7f0e')\r\n",
        "    x1, x2 = np.meshgrid(np.arange(-5.5, 1.0, 0.1), np.arange(-3.0, 1.0, 0.1))\r\n",
        "    plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\r\n",
        "    plt.xlabel('x1')\r\n",
        "    plt.ylabel('x2')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ######################################## 7.3 ###############################################\r\n",
        "def get_data_ch7():  \r\n",
        "    data = np.genfromtxt('../../data/airfoil_self_noise.dat', delimiter='\\t')\r\n",
        "    data = (data - data.mean(axis=0)) / data.std(axis=0)\r\n",
        "    return torch.tensor(data[:1500, :-1], dtype=torch.float32), \\\r\n",
        "        torch.tensor(data[:1500, -1], dtype=torch.float32) # 前1500个样本(每个样本5个特征)\r\n",
        "\r\n",
        "def train_ch7(optimizer_fn, states, hyperparams, features, labels,\r\n",
        "              batch_size=10, num_epochs=2):\r\n",
        "    # 初始化模型\r\n",
        "    net, loss = linreg, squared_loss\r\n",
        "    \r\n",
        "    w = torch.nn.Parameter(torch.tensor(np.random.normal(0, 0.01, size=(features.shape[1], 1)), dtype=torch.float32),\r\n",
        "                           requires_grad=True)\r\n",
        "    b = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32), requires_grad=True)\r\n",
        "\r\n",
        "    def eval_loss():\r\n",
        "        return loss(net(features, w, b), labels).mean().item()\r\n",
        "\r\n",
        "    ls = [eval_loss()]\r\n",
        "    data_iter = torch.utils.data.DataLoader(\r\n",
        "        torch.utils.data.TensorDataset(features, labels), batch_size, shuffle=True)\r\n",
        "    \r\n",
        "    for _ in range(num_epochs):\r\n",
        "        start = time.time()\r\n",
        "        for batch_i, (X, y) in enumerate(data_iter):\r\n",
        "            l = loss(net(X, w, b), y).mean()  # 使用平均损失\r\n",
        "            \r\n",
        "            # 梯度清零\r\n",
        "            if w.grad is not None:\r\n",
        "                w.grad.data.zero_()\r\n",
        "                b.grad.data.zero_()\r\n",
        "                \r\n",
        "            l.backward()\r\n",
        "            optimizer_fn([w, b], states, hyperparams)  # 迭代模型参数\r\n",
        "            if (batch_i + 1) * batch_size % 100 == 0:\r\n",
        "                ls.append(eval_loss())  # 每100个样本记录下当前训练误差\r\n",
        "    # 打印结果和作图\r\n",
        "    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\r\n",
        "    set_figsize()\r\n",
        "    plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\r\n",
        "    plt.xlabel('epoch')\r\n",
        "    plt.ylabel('loss')\r\n",
        "\r\n",
        "# 本函数与原书不同的是这里第一个参数优化器函数而不是优化器的名字\r\n",
        "# 例如: optimizer_fn=torch.optim.SGD, optimizer_hyperparams={\"lr\": 0.05}\r\n",
        "def train_pytorch_ch7(optimizer_fn, optimizer_hyperparams, features, labels,\r\n",
        "                    batch_size=10, num_epochs=2):\r\n",
        "    # 初始化模型\r\n",
        "    net = nn.Sequential(\r\n",
        "        nn.Linear(features.shape[-1], 1)\r\n",
        "    )\r\n",
        "    loss = nn.MSELoss()\r\n",
        "    optimizer = optimizer_fn(net.parameters(), **optimizer_hyperparams)\r\n",
        "\r\n",
        "    def eval_loss():\r\n",
        "        return loss(net(features).view(-1), labels).item() / 2\r\n",
        "\r\n",
        "    ls = [eval_loss()]\r\n",
        "    data_iter = torch.utils.data.DataLoader(\r\n",
        "        torch.utils.data.TensorDataset(features, labels), batch_size, shuffle=True)\r\n",
        "\r\n",
        "    for _ in range(num_epochs):\r\n",
        "        start = time.time()\r\n",
        "        for batch_i, (X, y) in enumerate(data_iter):\r\n",
        "            # 除以2是为了和train_ch7保持一致, 因为squared_loss中除了2\r\n",
        "            l = loss(net(X).view(-1), y) / 2 \r\n",
        "            \r\n",
        "            optimizer.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            optimizer.step()\r\n",
        "            if (batch_i + 1) * batch_size % 100 == 0:\r\n",
        "                ls.append(eval_loss())\r\n",
        "    # 打印结果和作图\r\n",
        "    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\r\n",
        "    set_figsize()\r\n",
        "    plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\r\n",
        "    plt.xlabel('epoch')\r\n",
        "    plt.ylabel('loss')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "############################## 8.3 ##################################\r\n",
        "class Benchmark():\r\n",
        "    def __init__(self, prefix=None):\r\n",
        "        self.prefix = prefix + ' ' if prefix else ''\r\n",
        "\r\n",
        "    def __enter__(self):\r\n",
        "        self.start = time.time()\r\n",
        "\r\n",
        "    def __exit__(self, *args):\r\n",
        "        print('%stime: %.4f sec' % (self.prefix, time.time() - self.start))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ########################### 9.1 ########################################\r\n",
        "def show_images(imgs, num_rows, num_cols, scale=2):\r\n",
        "    figsize = (num_cols * scale, num_rows * scale)\r\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\r\n",
        "    for i in range(num_rows):\r\n",
        "        for j in range(num_cols):\r\n",
        "            axes[i][j].imshow(imgs[i * num_cols + j])\r\n",
        "            axes[i][j].axes.get_xaxis().set_visible(False)\r\n",
        "            axes[i][j].axes.get_yaxis().set_visible(False)\r\n",
        "    return axes\r\n",
        "\r\n",
        "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\r\n",
        "    net = net.to(device)\r\n",
        "    print(\"training on \", device)\r\n",
        "    batch_count = 0\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\r\n",
        "        for X, y in train_iter:\r\n",
        "            X = X.to(device)\r\n",
        "            y = y.to(device)\r\n",
        "            y_hat = net(X)\r\n",
        "            l = loss(y_hat, y) \r\n",
        "            optimizer.zero_grad()\r\n",
        "            l.backward()\r\n",
        "            optimizer.step()\r\n",
        "            train_l_sum += l.cpu().item()\r\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\r\n",
        "            n += y.shape[0]\r\n",
        "            batch_count += 1\r\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\r\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\r\n",
        "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "############################## 9.3 #####################\r\n",
        "def bbox_to_rect(bbox, color):\r\n",
        "    # 将边界框(左上x, 左上y, 右下x, 右下y)格式转换成matplotlib格式：\r\n",
        "    # ((左上x, 左上y), 宽, 高)\r\n",
        "    return plt.Rectangle(\r\n",
        "        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\r\n",
        "        fill=False, edgecolor=color, linewidth=2)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "############################ 9.4 ###########################\r\n",
        "def MultiBoxPrior(feature_map, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5]):\r\n",
        "    \"\"\"\r\n",
        "    # 按照「9.4.1. 生成多个锚框」所讲的实现, anchor表示成(xmin, ymin, xmax, ymax).\r\n",
        "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\r\n",
        "    Args:\r\n",
        "        feature_map: torch tensor, Shape: [N, C, H, W].\r\n",
        "        sizes: List of sizes (0~1) of generated MultiBoxPriores. \r\n",
        "        ratios: List of aspect ratios (non-negative) of generated MultiBoxPriores. \r\n",
        "    Returns:\r\n",
        "        anchors of shape (1, num_anchors, 4). 由于batch里每个都一样, 所以第一维为1\r\n",
        "    \"\"\"\r\n",
        "    pairs = [] # pair of (size, sqrt(ration))\r\n",
        "    for r in ratios:\r\n",
        "        pairs.append([sizes[0], math.sqrt(r)])\r\n",
        "    for s in sizes[1:]:\r\n",
        "        pairs.append([s, math.sqrt(ratios[0])])\r\n",
        "    \r\n",
        "    pairs = np.array(pairs)\r\n",
        "    \r\n",
        "    ss1 = pairs[:, 0] * pairs[:, 1] # size * sqrt(ration)\r\n",
        "    ss2 = pairs[:, 0] / pairs[:, 1] # size / sqrt(ration)\r\n",
        "    \r\n",
        "    base_anchors = np.stack([-ss1, -ss2, ss1, ss2], axis=1) / 2\r\n",
        "    \r\n",
        "    h, w = feature_map.shape[-2:]\r\n",
        "    shifts_x = np.arange(0, w) / w\r\n",
        "    shifts_y = np.arange(0, h) / h\r\n",
        "    shift_x, shift_y = np.meshgrid(shifts_x, shifts_y)\r\n",
        "    shift_x = shift_x.reshape(-1)\r\n",
        "    shift_y = shift_y.reshape(-1)\r\n",
        "    shifts = np.stack((shift_x, shift_y, shift_x, shift_y), axis=1)\r\n",
        "    \r\n",
        "    anchors = shifts.reshape((-1, 1, 4)) + base_anchors.reshape((1, -1, 4))\r\n",
        "    \r\n",
        "    return torch.tensor(anchors, dtype=torch.float32).view(1, -1, 4)\r\n",
        "\r\n",
        "def show_bboxes(axes, bboxes, labels=None, colors=None):\r\n",
        "    def _make_list(obj, default_values=None):\r\n",
        "        if obj is None:\r\n",
        "            obj = default_values\r\n",
        "        elif not isinstance(obj, (list, tuple)):\r\n",
        "            obj = [obj]\r\n",
        "        return obj\r\n",
        "\r\n",
        "    labels = _make_list(labels)\r\n",
        "    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\r\n",
        "    for i, bbox in enumerate(bboxes):\r\n",
        "        color = colors[i % len(colors)]\r\n",
        "        rect = bbox_to_rect(bbox.detach().cpu().numpy(), color)\r\n",
        "        axes.add_patch(rect)\r\n",
        "        if labels and len(labels) > i:\r\n",
        "            text_color = 'k' if color == 'w' else 'w'\r\n",
        "            axes.text(rect.xy[0], rect.xy[1], labels[i],\r\n",
        "                      va='center', ha='center', fontsize=6, color=text_color,\r\n",
        "                      bbox=dict(facecolor=color, lw=0))\r\n",
        "\r\n",
        "def compute_intersection(set_1, set_2):\r\n",
        "    \"\"\"\r\n",
        "    计算anchor之间的交集\r\n",
        "    Args:\r\n",
        "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\r\n",
        "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\r\n",
        "    Returns:\r\n",
        "        intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\r\n",
        "    \"\"\"\r\n",
        "    # PyTorch auto-broadcasts singleton dimensions\r\n",
        "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\r\n",
        "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\r\n",
        "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\r\n",
        "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\r\n",
        "\r\n",
        "def compute_jaccard(set_1, set_2):\r\n",
        "    \"\"\"\r\n",
        "    计算anchor之间的Jaccard系数(IoU)\r\n",
        "    Args:\r\n",
        "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\r\n",
        "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\r\n",
        "    Returns:\r\n",
        "        Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\r\n",
        "    \"\"\"\r\n",
        "    # Find intersections\r\n",
        "    intersection = compute_intersection(set_1, set_2)  # (n1, n2)\r\n",
        "\r\n",
        "    # Find areas of each box in both sets\r\n",
        "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\r\n",
        "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\r\n",
        "\r\n",
        "    # Find the union\r\n",
        "    # PyTorch auto-broadcasts singleton dimensions\r\n",
        "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\r\n",
        "\r\n",
        "    return intersection / union  # (n1, n2)\r\n",
        "\r\n",
        "def assign_anchor(bb, anchor, jaccard_threshold=0.5):\r\n",
        "    \"\"\"\r\n",
        "    # 按照「9.4.1. 生成多个锚框」图9.3所讲为每个anchor分配真实的bb, anchor表示成归一化(xmin, ymin, xmax, ymax).\r\n",
        "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\r\n",
        "    Args:\r\n",
        "        bb: 真实边界框(bounding box), shape:（nb, 4）\r\n",
        "        anchor: 待分配的anchor, shape:（na, 4）\r\n",
        "        jaccard_threshold: 预先设定的阈值\r\n",
        "    Returns:\r\n",
        "        assigned_idx: shape: (na, ), 每个anchor分配的真实bb对应的索引, 若未分配任何bb则为-1\r\n",
        "    \"\"\"\r\n",
        "    na = anchor.shape[0]\r\n",
        "    nb = bb.shape[0]\r\n",
        "    jaccard = compute_jaccard(anchor, bb).detach().cpu().numpy() # shape: (na, nb)\r\n",
        "    assigned_idx = np.ones(na) * -1  # 初始全为-1\r\n",
        "    \r\n",
        "    # 先为每个bb分配一个anchor(不要求满足jaccard_threshold)\r\n",
        "    jaccard_cp = jaccard.copy()\r\n",
        "    for j in range(nb):\r\n",
        "        i = np.argmax(jaccard_cp[:, j])\r\n",
        "        assigned_idx[i] = j\r\n",
        "        jaccard_cp[i, :] = float(\"-inf\") # 赋值为负无穷, 相当于去掉这一行\r\n",
        "     \r\n",
        "    # 处理还未被分配的anchor, 要求满足jaccard_threshold\r\n",
        "    for i in range(na):\r\n",
        "        if assigned_idx[i] == -1:\r\n",
        "            j = np.argmax(jaccard[i, :])\r\n",
        "            if jaccard[i, j] >= jaccard_threshold:\r\n",
        "                assigned_idx[i] = j\r\n",
        "    \r\n",
        "    return torch.tensor(assigned_idx, dtype=torch.long)\r\n",
        "\r\n",
        "def xy_to_cxcy(xy):\r\n",
        "    \"\"\"\r\n",
        "    将(x_min, y_min, x_max, y_max)形式的anchor转换成(center_x, center_y, w, h)形式的.\r\n",
        "    https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py\r\n",
        "    Args:\r\n",
        "        xy: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\r\n",
        "    Returns: \r\n",
        "        bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\r\n",
        "    \"\"\"\r\n",
        "    return torch.cat([(xy[:, 2:] + xy[:, :2]) / 2,  # c_x, c_y\r\n",
        "                      xy[:, 2:] - xy[:, :2]], 1)  # w, h\r\n",
        "\r\n",
        "def MultiBoxTarget(anchor, label):\r\n",
        "    \"\"\"\r\n",
        "    # 按照「9.4.1. 生成多个锚框」所讲的实现, anchor表示成归一化(xmin, ymin, xmax, ymax).\r\n",
        "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\r\n",
        "    Args:\r\n",
        "        anchor: torch tensor, 输入的锚框, 一般是通过MultiBoxPrior生成, shape:（1，锚框总数，4）\r\n",
        "        label: 真实标签, shape为(bn, 每张图片最多的真实锚框数, 5)\r\n",
        "               第二维中，如果给定图片没有这么多锚框, 可以先用-1填充空白, 最后一维中的元素为[类别标签, 四个坐标值]\r\n",
        "    Returns:\r\n",
        "        列表, [bbox_offset, bbox_mask, cls_labels]\r\n",
        "        bbox_offset: 每个锚框的标注偏移量，形状为(bn，锚框总数*4)\r\n",
        "        bbox_mask: 形状同bbox_offset, 每个锚框的掩码, 一一对应上面的偏移量, 负类锚框(背景)对应的掩码均为0, 正类锚框的掩码均为1\r\n",
        "        cls_labels: 每个锚框的标注类别, 其中0表示为背景, 形状为(bn，锚框总数)\r\n",
        "    \"\"\"\r\n",
        "    assert len(anchor.shape) == 3 and len(label.shape) == 3\r\n",
        "    bn = label.shape[0]\r\n",
        "    \r\n",
        "    def MultiBoxTarget_one(anc, lab, eps=1e-6):\r\n",
        "        \"\"\"\r\n",
        "        MultiBoxTarget函数的辅助函数, 处理batch中的一个\r\n",
        "        Args:\r\n",
        "            anc: shape of (锚框总数, 4)\r\n",
        "            lab: shape of (真实锚框数, 5), 5代表[类别标签, 四个坐标值]\r\n",
        "            eps: 一个极小值, 防止log0\r\n",
        "        Returns:\r\n",
        "            offset: (锚框总数*4, )\r\n",
        "            bbox_mask: (锚框总数*4, ), 0代表背景, 1代表非背景\r\n",
        "            cls_labels: (锚框总数, 4), 0代表背景\r\n",
        "        \"\"\"\r\n",
        "        an = anc.shape[0]\r\n",
        "        assigned_idx = assign_anchor(lab[:, 1:], anc) # (锚框总数, )\r\n",
        "        bbox_mask = ((assigned_idx >= 0).float().unsqueeze(-1)).repeat(1, 4) # (锚框总数, 4)\r\n",
        "\r\n",
        "        cls_labels = torch.zeros(an, dtype=torch.long) # 0表示背景\r\n",
        "        assigned_bb = torch.zeros((an, 4), dtype=torch.float32) # 所有anchor对应的bb坐标\r\n",
        "        for i in range(an):\r\n",
        "            bb_idx = assigned_idx[i]\r\n",
        "            if bb_idx >= 0: # 即非背景\r\n",
        "                cls_labels[i] = lab[bb_idx, 0].long().item() + 1 # 注意要加一\r\n",
        "                assigned_bb[i, :] = lab[bb_idx, 1:]\r\n",
        "\r\n",
        "        center_anc = xy_to_cxcy(anc) # (center_x, center_y, w, h)\r\n",
        "        center_assigned_bb = xy_to_cxcy(assigned_bb)\r\n",
        "\r\n",
        "        offset_xy = 10.0 * (center_assigned_bb[:, :2] - center_anc[:, :2]) / center_anc[:, 2:]\r\n",
        "        offset_wh = 5.0 * torch.log(eps + center_assigned_bb[:, 2:] / center_anc[:, 2:])\r\n",
        "        offset = torch.cat([offset_xy, offset_wh], dim = 1) * bbox_mask # (锚框总数, 4)\r\n",
        "\r\n",
        "        return offset.view(-1), bbox_mask.view(-1), cls_labels\r\n",
        "    \r\n",
        "    batch_offset = []\r\n",
        "    batch_mask = []\r\n",
        "    batch_cls_labels = []\r\n",
        "    for b in range(bn):\r\n",
        "        offset, bbox_mask, cls_labels = MultiBoxTarget_one(anchor[0, :, :], label[b, :, :])\r\n",
        "        \r\n",
        "        batch_offset.append(offset)\r\n",
        "        batch_mask.append(bbox_mask)\r\n",
        "        batch_cls_labels.append(cls_labels)\r\n",
        "    \r\n",
        "    bbox_offset = torch.stack(batch_offset)\r\n",
        "    bbox_mask = torch.stack(batch_mask)\r\n",
        "    cls_labels = torch.stack(batch_cls_labels)\r\n",
        "    \r\n",
        "    return [bbox_offset, bbox_mask, cls_labels]\r\n",
        "\r\n",
        "\r\n",
        "Pred_BB_Info = namedtuple(\"Pred_BB_Info\", [\"index\", \"class_id\", \"confidence\", \"xyxy\"])\r\n",
        "def non_max_suppression(bb_info_list, nms_threshold = 0.5):\r\n",
        "    \"\"\"\r\n",
        "    非极大抑制处理预测的边界框\r\n",
        "    Args:\r\n",
        "        bb_info_list: Pred_BB_Info的列表, 包含预测类别、置信度等信息\r\n",
        "        nms_threshold: 阈值\r\n",
        "    Returns:\r\n",
        "        output: Pred_BB_Info的列表, 只保留过滤后的边界框信息\r\n",
        "    \"\"\"\r\n",
        "    output = []\r\n",
        "    # 先根据置信度从高到低排序\r\n",
        "    sorted_bb_info_list = sorted(bb_info_list, key = lambda x: x.confidence, reverse=True)\r\n",
        "\r\n",
        "    while len(sorted_bb_info_list) != 0:\r\n",
        "        best = sorted_bb_info_list.pop(0)\r\n",
        "        output.append(best)\r\n",
        "        \r\n",
        "        if len(sorted_bb_info_list) == 0:\r\n",
        "            break\r\n",
        "\r\n",
        "        bb_xyxy = []\r\n",
        "        for bb in sorted_bb_info_list:\r\n",
        "            bb_xyxy.append(bb.xyxy)\r\n",
        "        \r\n",
        "        iou = compute_jaccard(torch.tensor([best.xyxy]), \r\n",
        "                              torch.tensor(bb_xyxy))[0] # shape: (len(sorted_bb_info_list), )\r\n",
        "        \r\n",
        "        n = len(sorted_bb_info_list)\r\n",
        "        sorted_bb_info_list = [sorted_bb_info_list[i] for i in range(n) if iou[i] <= nms_threshold]\r\n",
        "    return output\r\n",
        "\r\n",
        "def MultiBoxDetection(cls_prob, loc_pred, anchor, nms_threshold = 0.5):\r\n",
        "    \"\"\"\r\n",
        "    # 按照「9.4.1. 生成多个锚框」所讲的实现, anchor表示成归一化(xmin, ymin, xmax, ymax).\r\n",
        "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\r\n",
        "    Args:\r\n",
        "        cls_prob: 经过softmax后得到的各个锚框的预测概率, shape:(bn, 预测总类别数+1, 锚框个数)\r\n",
        "        loc_pred: 预测的各个锚框的偏移量, shape:(bn, 锚框个数*4)\r\n",
        "        anchor: MultiBoxPrior输出的默认锚框, shape: (1, 锚框个数, 4)\r\n",
        "        nms_threshold: 非极大抑制中的阈值\r\n",
        "    Returns:\r\n",
        "        所有锚框的信息, shape: (bn, 锚框个数, 6)\r\n",
        "        每个锚框信息由[class_id, confidence, xmin, ymin, xmax, ymax]表示\r\n",
        "        class_id=-1 表示背景或在非极大值抑制中被移除了\r\n",
        "    \"\"\"\r\n",
        "    assert len(cls_prob.shape) == 3 and len(loc_pred.shape) == 2 and len(anchor.shape) == 3\r\n",
        "    bn = cls_prob.shape[0]\r\n",
        "    \r\n",
        "    def MultiBoxDetection_one(c_p, l_p, anc, nms_threshold = 0.5):\r\n",
        "        \"\"\"\r\n",
        "        MultiBoxDetection的辅助函数, 处理batch中的一个\r\n",
        "        Args:\r\n",
        "            c_p: (预测总类别数+1, 锚框个数)\r\n",
        "            l_p: (锚框个数*4, )\r\n",
        "            anc: (锚框个数, 4)\r\n",
        "            nms_threshold: 非极大抑制中的阈值\r\n",
        "        Return:\r\n",
        "            output: (锚框个数, 6)\r\n",
        "        \"\"\"\r\n",
        "        pred_bb_num = c_p.shape[1]\r\n",
        "        anc = (anc + l_p.view(pred_bb_num, 4)).detach().cpu().numpy() # 加上偏移量\r\n",
        "        \r\n",
        "        confidence, class_id = torch.max(c_p, 0)\r\n",
        "        confidence = confidence.detach().cpu().numpy()\r\n",
        "        class_id = class_id.detach().cpu().numpy()\r\n",
        "        \r\n",
        "        pred_bb_info = [Pred_BB_Info(\r\n",
        "                            index = i,\r\n",
        "                            class_id = class_id[i] - 1, # 正类label从0开始\r\n",
        "                            confidence = confidence[i],\r\n",
        "                            xyxy=[*anc[i]]) # xyxy是个列表\r\n",
        "                        for i in range(pred_bb_num)]\r\n",
        "        \r\n",
        "        # 正类的index\r\n",
        "        obj_bb_idx = [bb.index for bb in non_max_suppression(pred_bb_info, nms_threshold)]\r\n",
        "        \r\n",
        "        output = []\r\n",
        "        for bb in pred_bb_info:\r\n",
        "            output.append([\r\n",
        "                (bb.class_id if bb.index in obj_bb_idx else -1.0),\r\n",
        "                bb.confidence,\r\n",
        "                *bb.xyxy\r\n",
        "            ])\r\n",
        "            \r\n",
        "        return torch.tensor(output) # shape: (锚框个数, 6)\r\n",
        "    \r\n",
        "    batch_output = []\r\n",
        "    for b in range(bn):\r\n",
        "        batch_output.append(MultiBoxDetection_one(cls_prob[b], loc_pred[b], anchor[0], nms_threshold))\r\n",
        "    \r\n",
        "    return torch.stack(batch_output)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ################################# 9.6 ############################\r\n",
        "class PikachuDetDataset(torch.utils.data.Dataset):\r\n",
        "    \"\"\"皮卡丘检测数据集类\"\"\"\r\n",
        "    def __init__(self, data_dir, part, image_size=(256, 256)):\r\n",
        "        assert part in [\"train\", \"val\"]\r\n",
        "        self.image_size = image_size\r\n",
        "        self.image_dir = os.path.join(data_dir, part, \"images\")\r\n",
        "        \r\n",
        "        with open(os.path.join(data_dir, part, \"label.json\")) as f:\r\n",
        "            self.label = json.load(f)\r\n",
        "            \r\n",
        "        self.transform = torchvision.transforms.Compose([\r\n",
        "            # 将 PIL 图片转换成位于[0.0, 1.0]的floatTensor, shape (C x H x W)\r\n",
        "            torchvision.transforms.ToTensor()])\r\n",
        "            \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.label)\r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        image_path = str(index + 1) + \".png\"\r\n",
        "        \r\n",
        "        cls = self.label[image_path][\"class\"]\r\n",
        "        label = np.array([cls] + self.label[image_path][\"loc\"], \r\n",
        "                         dtype=\"float32\")[None, :]\r\n",
        "        \r\n",
        "        PIL_img = Image.open(os.path.join(self.image_dir, image_path)\r\n",
        "                            ).convert('RGB').resize(self.image_size)\r\n",
        "        img = self.transform(PIL_img)\r\n",
        "        \r\n",
        "        sample = {\r\n",
        "            \"label\": label, # shape: (1, 5) [class, xmin, ymin, xmax, ymax]\r\n",
        "            \"image\": img    # shape: (3, *image_size)\r\n",
        "        }\r\n",
        "        \r\n",
        "        return sample\r\n",
        "\r\n",
        "def load_data_pikachu(batch_size, edge_size=256, data_dir = '../../data/pikachu'):  \r\n",
        "    \"\"\"edge_size：输出图像的宽和高\"\"\"\r\n",
        "    image_size = (edge_size, edge_size)\r\n",
        "    train_dataset = PikachuDetDataset(data_dir, 'train', image_size)\r\n",
        "    val_dataset = PikachuDetDataset(data_dir, 'val', image_size)\r\n",
        "    \r\n",
        "\r\n",
        "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \r\n",
        "                                             shuffle=True, num_workers=4)\r\n",
        "\r\n",
        "    val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\r\n",
        "                                           shuffle=False, num_workers=4)\r\n",
        "    return train_iter, val_iter\r\n",
        "\r\n",
        "\r\n",
        "# ################################# 9.9 #########################\r\n",
        "def read_voc_images(root=\"../../data/VOCdevkit/VOC2012\", \r\n",
        "                    is_train=True, max_num=None):\r\n",
        "    txt_fname = '%s/ImageSets/Segmentation/%s' % (\r\n",
        "        root, 'train.txt' if is_train else 'val.txt')\r\n",
        "    with open(txt_fname, 'r') as f:\r\n",
        "        images = f.read().split()\r\n",
        "    if max_num is not None:\r\n",
        "        images = images[:min(max_num, len(images))]\r\n",
        "    features, labels = [None] * len(images), [None] * len(images)\r\n",
        "    for i, fname in tqdm(enumerate(images)):\r\n",
        "        features[i] = Image.open('%s/JPEGImages/%s.jpg' % (root, fname)).convert(\"RGB\")\r\n",
        "        labels[i] = Image.open('%s/SegmentationClass/%s.png' % (root, fname)).convert(\"RGB\")\r\n",
        "    return features, labels # PIL image\r\n",
        "\r\n",
        "# colormap2label = torch.zeros(256 ** 3, dtype=torch.uint8)\r\n",
        "# for i, colormap in enumerate(VOC_COLORMAP):\r\n",
        "#     colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\r\n",
        "def voc_label_indices(colormap, colormap2label):\r\n",
        "    \"\"\"\r\n",
        "    convert colormap (PIL image) to colormap2label (uint8 tensor).\r\n",
        "    \"\"\"\r\n",
        "    colormap = np.array(colormap.convert(\"RGB\")).astype('int32')\r\n",
        "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\r\n",
        "           + colormap[:, :, 2])\r\n",
        "    return colormap2label[idx]\r\n",
        "\r\n",
        "def voc_rand_crop(feature, label, height, width):\r\n",
        "    \"\"\"\r\n",
        "    Random crop feature (PIL image) and label (PIL image).\r\n",
        "    \"\"\"\r\n",
        "    i, j, h, w = torchvision.transforms.RandomCrop.get_params(\r\n",
        "            feature, output_size=(height, width))\r\n",
        "    \r\n",
        "    feature = torchvision.transforms.functional.crop(feature, i, j, h, w)\r\n",
        "    label = torchvision.transforms.functional.crop(label, i, j, h, w)    \r\n",
        "\r\n",
        "    return feature, label\r\n",
        "\r\n",
        "class VOCSegDataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, is_train, crop_size, voc_dir, colormap2label, max_num=None):\r\n",
        "        \"\"\"\r\n",
        "        crop_size: (h, w)\r\n",
        "        \"\"\"\r\n",
        "        self.rgb_mean = np.array([0.485, 0.456, 0.406])\r\n",
        "        self.rgb_std = np.array([0.229, 0.224, 0.225])\r\n",
        "        self.tsf = torchvision.transforms.Compose([\r\n",
        "            torchvision.transforms.ToTensor(),\r\n",
        "            torchvision.transforms.Normalize(mean=self.rgb_mean, \r\n",
        "                                             std=self.rgb_std)\r\n",
        "        ])\r\n",
        "        \r\n",
        "        self.crop_size = crop_size # (h, w)\r\n",
        "        features, labels = read_voc_images(root=voc_dir, \r\n",
        "                                           is_train=is_train, \r\n",
        "                                           max_num=max_num)\r\n",
        "        self.features = self.filter(features) # PIL image\r\n",
        "        self.labels = self.filter(labels)     # PIL image\r\n",
        "        self.colormap2label = colormap2label\r\n",
        "        print('read ' + str(len(self.features)) + ' valid examples')\r\n",
        "\r\n",
        "    def filter(self, imgs):\r\n",
        "        return [img for img in imgs if (\r\n",
        "            img.size[1] >= self.crop_size[0] and\r\n",
        "            img.size[0] >= self.crop_size[1])]\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\r\n",
        "                                       *self.crop_size)\r\n",
        "        \r\n",
        "        return (self.tsf(feature),\r\n",
        "                voc_label_indices(label, self.colormap2label))\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.features)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# ############################# 10.7 ##########################\r\n",
        "def read_imdb(folder='train', data_root=\"/S1/CSCL/tangss/Datasets/aclImdb\"): \r\n",
        "    data = []\r\n",
        "    for label in ['pos', 'neg']:\r\n",
        "        folder_name = os.path.join(data_root, folder, label)\r\n",
        "        for file in tqdm(os.listdir(folder_name)):\r\n",
        "            with open(os.path.join(folder_name, file), 'rb') as f:\r\n",
        "                review = f.read().decode('utf-8').replace('\\n', '').lower()\r\n",
        "                data.append([review, 1 if label == 'pos' else 0])\r\n",
        "    random.shuffle(data)\r\n",
        "    return data\r\n",
        "\r\n",
        "def get_tokenized_imdb(data):\r\n",
        "    \"\"\"\r\n",
        "    data: list of [string, label]\r\n",
        "    \"\"\"\r\n",
        "    def tokenizer(text):\r\n",
        "        return [tok.lower() for tok in text.split(' ')]\r\n",
        "    return [tokenizer(review) for review, _ in data]\r\n",
        "\r\n",
        "def get_vocab_imdb(data):\r\n",
        "    tokenized_data = get_tokenized_imdb(data)\r\n",
        "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\r\n",
        "    return torchtext.vocab.Vocab(counter, min_freq=5)\r\n",
        "\r\n",
        "def preprocess_imdb(data, vocab):\r\n",
        "    max_l = 500  # 将每条评论通过截断或者补0，使得长度变成500\r\n",
        "\r\n",
        "    def pad(x):\r\n",
        "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\r\n",
        "\r\n",
        "    tokenized_data = get_tokenized_imdb(data)\r\n",
        "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\r\n",
        "    labels = torch.tensor([score for _, score in data])\r\n",
        "    return features, labels\r\n",
        "\r\n",
        "def load_pretrained_embedding(words, pretrained_vocab):\r\n",
        "    \"\"\"从预训练好的vocab中提取出words对应的词向量\"\"\"\r\n",
        "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # 初始化为0\r\n",
        "    oov_count = 0 # out of vocabulary\r\n",
        "    for i, word in enumerate(words):\r\n",
        "        try:\r\n",
        "            idx = pretrained_vocab.stoi[word]\r\n",
        "            embed[i, :] = pretrained_vocab.vectors[idx]\r\n",
        "        except KeyError:\r\n",
        "            oov_count += 1\r\n",
        "    if oov_count > 0:\r\n",
        "        print(\"There are %d oov words.\" % oov_count)\r\n",
        "    return embed\r\n",
        "\r\n",
        "def predict_sentiment(net, vocab, sentence):\r\n",
        "    \"\"\"sentence是词语的列表\"\"\"\r\n",
        "    device = list(net.parameters())[0].device\r\n",
        "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\r\n",
        "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\r\n",
        "    return 'positive' if label.item() == 1 else 'negative'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v9dcGyvJQ6q",
        "outputId": "79c54b04-d3bc-44d4-e96f-00838e23fc09"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb 16 09:22:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QBOmeYyJaw3"
      },
      "source": [
        "class AlexNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(AlexNet,self).__init__()\r\n",
        "        self.conv = nn.Sequential(\r\n",
        "            nn.Conv2d(1,96,11,4),# in_channels, out_channels, kernel_size, stride\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(3,2), #kernel_size,stride\r\n",
        "            #减小卷积窗口，使用填充2来使得输入与输出的高和宽一直，且增大输出通道数量\r\n",
        "            nn.Conv2d(96,256,5,1,2), #in_channels,out_channels,kernel_size,stride,padding\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(3,2),\r\n",
        "            # 连续三个卷积层，且使用更小的卷积窗口，除了最后的卷积层以外，进一步增大了输出通道数量\r\n",
        "            # 前两个卷积层后不适用池化层来减小输入的高和宽\r\n",
        "            nn.Conv2d(256,384,3,1,1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(384,384,3,1,1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Conv2d(384,256,3,1,1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(3,2)\r\n",
        "        )\r\n",
        "        # 这里的全连接层的输出个数比LeNet中的大数倍，使用dropout来缓解过拟合\r\n",
        "        self.fc = nn.Sequential(\r\n",
        "            nn.Linear(256*5*5,4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "            nn.Linear(4096,4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "            # 输出层，由于这里使用fashion-mnist，所以类别数量为10，而非论文中的1000\r\n",
        "            nn.Linear(4096,10),\r\n",
        "        )\r\n",
        "    def forward(self,img):\r\n",
        "        feature = self.conv(img)\r\n",
        "        output = self.fc(feature.view(img.shape[0],-1))\r\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krSs93gjMveH",
        "outputId": "d5782680-84af-4295-a4fb-d2ad712fb69a"
      },
      "source": [
        "net = AlexNet()\r\n",
        "print(net)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK0VBdJSMu-A"
      },
      "source": [
        "## 3. 读取数据\r\n",
        "\r\n",
        "虽然论文中AlexNet使用ImageNet数据集，但因为ImageNet数据集训练时间较长，我们仍用前面的Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过torchvision.transforms.Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399,
          "referenced_widgets": [
            "4eb41d5f625d4c8c8f5d172ddb19fda9",
            "3994679f06b641d09a6e8e6a322f6dbb",
            "0f35cd3628c44ffaa1a92a66866ade7b",
            "617f37e30ea84c5d9cd57082539e7360",
            "e9ad77fb346348d69f2f1abba084b266",
            "808ffb7935534233becb9c7e94846893",
            "6d13e0cc7846466d9b21f022682459ca",
            "ac783a184d0042abbf33852901898c5f",
            "da1a3c490f74488493299b5a3b54649f",
            "c8518a1e2572492a8e33108dbe8de9b6",
            "ee6eea83dde945f0b7d8e8ff4198b3fe",
            "0367a080bf864717a11f603c6c50aa69",
            "2e8f0172290a40148261e1b205372be7",
            "af509a94b3324dbaa164ae8f034f0d57",
            "2ac7c06a7a84481a9094b09b0de4448c",
            "314108679d124a75a8078ec4d5b79019",
            "289418baa87a4d9bb85b2e530245acc5",
            "90ddcdaf081b4fd8b342476bdd8cda06",
            "8eccad20ce11449a956952d8c417b45f",
            "9e2a2ec770054c32adc238cf8935c733",
            "22bf3cffde1c472098d7f0c77c5c38ae",
            "a0ecee9467e84070b275696e79008a34",
            "bc1448c158b743da99decc08ef235213",
            "1a3047300508447bbc172ae06d47e849",
            "a018591ca8a04884a2dfa98e61bc004b",
            "119bc2da7f3e4bc785a08dd2affbc3ce",
            "b7a14b74f66c4e5db10a3849dd7c60f6",
            "deca761bbb3c47a08ff6cd6f19542fbf",
            "6eeb036ea69145a38b04a9df7cec8a94",
            "06403622ee764938849edde472a22ba1",
            "9de8f34840dd428d9f119b8b0fdffa2a",
            "9e6dbc9a2c464185ba79f34442d27d99"
          ]
        },
        "id": "K4cSITfyM_mS",
        "outputId": "c95abdff-920d-4cc5-8bab-249db995f77a"
      },
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'):\r\n",
        "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\r\n",
        "    trans = []\r\n",
        "    if resize:\r\n",
        "        trans.append(torchvision.transforms.Resize(size=resize))\r\n",
        "    trans.append(torchvision.transforms.ToTensor())\r\n",
        "\r\n",
        "    transform = torchvision.transforms.Compose(trans)\r\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\r\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\r\n",
        "\r\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\r\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\r\n",
        "\r\n",
        "    return train_iter, test_iter\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "# 如出现“out of memory”的报错信息，可减小batch_size或resize\r\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eb41d5f625d4c8c8f5d172ddb19fda9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da1a3c490f74488493299b5a3b54649f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "289418baa87a4d9bb85b2e530245acc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a018591ca8a04884a2dfa98e61bc004b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/Datasets/FashionMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAAQht30NuNS"
      },
      "source": [
        "## 4.训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j1-IT2INwtA",
        "outputId": "5f66f688-8932-4dc5-9bf7-c7a2f2fcaa01"
      },
      "source": [
        "lr, num_epochs = 0.001, 5\r\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\r\n",
        "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on  cuda\n",
            "epoch 1, loss 0.6172, train acc 0.763, test acc 0.851, time 50.9 sec\n",
            "epoch 2, loss 0.3393, train acc 0.874, test acc 0.887, time 51.8 sec\n",
            "epoch 3, loss 0.2920, train acc 0.892, test acc 0.892, time 52.9 sec\n",
            "epoch 4, loss 0.2717, train acc 0.901, test acc 0.897, time 52.6 sec\n",
            "epoch 5, loss 0.2484, train acc 0.907, test acc 0.905, time 52.7 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0x00_tensor基本操作.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjJohatY+NIQlnK1Am3+Z4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matrixmax/Dive_into_DeepLearning/blob/main/0x00_tensor%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8lf62jTaPy5"
      },
      "source": [
        "import torch\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGKudjWZJcLB"
      },
      "source": [
        "## 1.创建tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGBx8qJxHHc6",
        "outputId": "5ed3189e-0ddd-4fa5-fc48-8948aa7a9808"
      },
      "source": [
        "x = torch.empty(5,3)\r\n",
        "print(x)\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.6977e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 7.0374e+22, 2.6323e-36]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_u3uo2fHjVq",
        "outputId": "5a3c371e-04ce-4f0a-ea58-f45dbf4d4422"
      },
      "source": [
        "x = torch.rand(5,3)\r\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0012, 0.7837, 0.1374],\n",
            "        [0.2017, 0.1614, 0.8177],\n",
            "        [0.9012, 0.3619, 0.8841],\n",
            "        [0.8289, 0.3633, 0.9065],\n",
            "        [0.5360, 0.3352, 0.4287]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2cuziZLHpl4",
        "outputId": "7682d730-e0e1-4842-c0de-716e6911621f"
      },
      "source": [
        "x = torch.zeros(5,3,dtype=torch.long)\r\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUXmb4RiHzBF",
        "outputId": "012a1868-b79b-471f-9a31-4e320c649e3e"
      },
      "source": [
        "x = torch.tensor([5.5,3])\r\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTO3XGgNIbfl",
        "outputId": "9f77cad8-b927-4e59-eedb-7d700a13d973"
      },
      "source": [
        "\r\n",
        "x = x.new_ones(5, 3, dtype=torch.float64)  # 返回的tensor默认具有相同的torch.dtype和torch.device\r\n",
        "print(x)\r\n",
        "\r\n",
        "x = torch.randn_like(x, dtype=torch.float) # 指定新的数据类型\r\n",
        "print(x) \r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 0.2367,  0.2240,  0.6341],\n",
            "        [ 2.1417,  0.5576,  0.1896],\n",
            "        [ 0.4114, -0.9129, -1.7366],\n",
            "        [ 0.0765, -0.0356,  0.2820],\n",
            "        [-1.8124,  0.7957, -1.4066]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGPEKbzXIc5E",
        "outputId": "aa02769f-028d-4423-b891-6dec435b4ca6"
      },
      "source": [
        "print(x.size())\r\n",
        "print(x.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xImYwXKJhQF"
      },
      "source": [
        "## 2.tensor操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hliK8x-FJpRP"
      },
      "source": [
        "### 2.1 算术操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir3AjiDvJF4Y",
        "outputId": "a47049d1-7f54-42d6-a7c2-2adecf23d056"
      },
      "source": [
        "y = torch.rand(5,3)\r\n",
        "print(x+y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9399,  0.5442,  0.7103],\n",
            "        [ 2.8612,  1.4721,  0.8289],\n",
            "        [ 0.8528, -0.4052, -0.8559],\n",
            "        [ 0.5521,  0.5211,  1.2597],\n",
            "        [-0.9525,  1.5135, -1.4050]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8efvV7WAJxQb",
        "outputId": "4f8ff643-ade6-4b92-c961-89f23f6de429"
      },
      "source": [
        "print(torch.add(x, y)) #另一种加法形式\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9399,  0.5442,  0.7103],\n",
            "        [ 2.8612,  1.4721,  0.8289],\n",
            "        [ 0.8528, -0.4052, -0.8559],\n",
            "        [ 0.5521,  0.5211,  1.2597],\n",
            "        [-0.9525,  1.5135, -1.4050]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEnCx4i9KU8p",
        "outputId": "2810cc78-6802-436b-a573-d8bbaacabb64"
      },
      "source": [
        "result = torch.empty(5, 3)\r\n",
        "torch.add(x, y, out=result)\r\n",
        "print(result)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9399,  0.5442,  0.7103],\n",
            "        [ 2.8612,  1.4721,  0.8289],\n",
            "        [ 0.8528, -0.4052, -0.8559],\n",
            "        [ 0.5521,  0.5211,  1.2597],\n",
            "        [-0.9525,  1.5135, -1.4050]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGH02zi6KezG"
      },
      "source": [
        "### 2.2 索引\r\n",
        "我们还可以使用类似NumPy的索引操作来访问Tensor的一部分，需要注意的是：**索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj0xIuZAKhjK",
        "outputId": "6f9308cc-202d-4b52-e68c-09fe2da5fd5a"
      },
      "source": [
        "print(x[0,:])\r\n",
        "y = x[0,:]\r\n",
        "y+=1\r\n",
        "print(y)\r\n",
        "print(x[0,:])  # 源tensor也被改了"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2367, 0.2240, 0.6341])\n",
            "tensor([1.2367, 1.2240, 1.6341])\n",
            "tensor([1.2367, 1.2240, 1.6341])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma4FF5ebLPac"
      },
      "source": [
        "### 2.3 改变形状\r\n",
        "用view() 来改变形状"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y13uASXPLMJC",
        "outputId": "82d25d19-07fc-478a-a8fb-3c660899aef5"
      },
      "source": [
        "y = x.view(15)\r\n",
        "z = x.view(-1,5) # -1所指的维度可以根据其他维度的值推出来\r\n",
        "print(x.size(),y.size(),z.size())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_oIKtVjLqqh"
      },
      "source": [
        "**注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USOJcmhPLoUW",
        "outputId": "970f680a-48de-4d5a-a430-a99772f6c646"
      },
      "source": [
        "x += 1\r\n",
        "print(x)\r\n",
        "print(y) # 也加了1\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.2367,  2.2240,  2.6341],\n",
            "        [ 3.1417,  1.5576,  1.1896],\n",
            "        [ 1.4114,  0.0871, -0.7366],\n",
            "        [ 1.0765,  0.9644,  1.2820],\n",
            "        [-0.8124,  1.7957, -0.4066]])\n",
            "tensor([ 2.2367,  2.2240,  2.6341,  3.1417,  1.5576,  1.1896,  1.4114,  0.0871,\n",
            "        -0.7366,  1.0765,  0.9644,  1.2820, -0.8124,  1.7957, -0.4066])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nimt4P4WMSOQ"
      },
      "source": [
        "所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？Pytorch还提供了一个reshape()可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用clone创造一个副本然后再使用view。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQtzmCyLMRtl",
        "outputId": "1303924f-ab47-4e21-96ab-2adeafd39bb7"
      },
      "source": [
        "x_cp = x.clone().view(15)\r\n",
        "x_=1\r\n",
        "print(x)\r\n",
        "print(x_cp)\r\n",
        "print(x_cp.size())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.2367,  2.2240,  2.6341],\n",
            "        [ 3.1417,  1.5576,  1.1896],\n",
            "        [ 1.4114,  0.0871, -0.7366],\n",
            "        [ 1.0765,  0.9644,  1.2820],\n",
            "        [-0.8124,  1.7957, -0.4066]])\n",
            "tensor([ 2.2367,  2.2240,  2.6341,  3.1417,  1.5576,  1.1896,  1.4114,  0.0871,\n",
            "        -0.7366,  1.0765,  0.9644,  1.2820, -0.8124,  1.7957, -0.4066])\n",
            "torch.Size([15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsFhMevAMlM4"
      },
      "source": [
        "另外一个常用的函数就是item(), 它可以将一个标量Tensor转换成一个Python number："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rw5lH4lMhqc",
        "outputId": "20a10680-8a62-467c-f5bc-c3150b9ced27"
      },
      "source": [
        "x = torch.randn(1)\r\n",
        "print(x)\r\n",
        "print(x.item())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6508])\n",
            "0.6507542133331299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhtxHGwgM-Pw"
      },
      "source": [
        "## 3.广播机制"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef2d7fk3N4AO"
      },
      "source": [
        "前面我们看到如何对两个形状相同的Tensor做按元素运算。当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。例如："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKHuAXk5NBdh",
        "outputId": "e04e14a1-b452-4150-f0ee-e8aa0c59b519"
      },
      "source": [
        "x = torch.arange(1, 3).view(1, 2)\r\n",
        "print(x)\r\n",
        "y = torch.arange(1, 4).view(3, 1)\r\n",
        "print(y)\r\n",
        "print(x + y)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[2, 3],\n",
            "        [3, 4],\n",
            "        [4, 5]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFb-HemAdXxO"
      },
      "source": [
        "由于x和y分别是1行2列和3行1列的矩阵，如果要计算x + y，那么x中第一行的2个元素被广播（复制）到了第二行和第三行，而y中第一列的3个元素被广播（复制）到了第二列。如此，就可以对2个3行2列的矩阵按元素相加。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxpE8ZnAeZAg"
      },
      "source": [
        "## 4.运算的内存开销"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWQF0W4elSq"
      },
      "source": [
        "前面说了，索引操作是不会开辟新内存的，而像y = x + y这样的运算是会新开内存的，然后将y指向新内存。为了演示这一点，我们可以使用Python自带的id函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72r-ke0adXRl",
        "outputId": "60543adb-b09f-4a9b-fdbc-c8c857c70c68"
      },
      "source": [
        "x = torch.tensor([1,2])\r\n",
        "y = torch.tensor([3,4])\r\n",
        "id_before = id(y)\r\n",
        "y=y+x\r\n",
        "print(id(y)==id_before)# False "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3zb9ZIHe_Ph"
      },
      "source": [
        "如果想指定结果到原来的y的内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们把x + y的结果通过[:]写进y对应的内存中。\r\n",
        "\r\n",
        "注：虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y3zFb0ae_xN",
        "outputId": "63111022-25a6-4b68-8093-07234fb84785"
      },
      "source": [
        "x = torch.tensor([1, 2])\r\n",
        "y = torch.tensor([3, 4])\r\n",
        "id_before = id(y)\r\n",
        "y[:] = y + x\r\n",
        "print(id(y) == id_before) # True\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDYbLDz9gM2K"
      },
      "source": [
        "## 5.tensor和numpy的互相转换"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG84VKGKgTqZ"
      },
      "source": [
        "我们很容易用numpy()和from_numpy()将Tensor和NumPy中的数组相互转换。但是需要注意的一点是： **这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！**\r\n",
        "\r\n",
        "还有一个常用的将NumPy中的array转换成Tensor的方法就是torch.tensor(), 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7hVy6l8gLQX",
        "outputId": "828df0d5-366d-49c4-bee9-af1dd061a47f"
      },
      "source": [
        "a = torch.ones(5)\r\n",
        "b = a.numpy()\r\n",
        "print(a,b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpdO5Za0f2jA",
        "outputId": "ec0fa96f-9a05-446c-aaf8-d7b785141eba"
      },
      "source": [
        "a+=1\r\n",
        "print(a,b)\r\n",
        "b+=1\r\n",
        "print(a,b)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
            "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9RG-c9jx1G_"
      },
      "source": [
        "numpy转tensor\r\n",
        "\r\n",
        "使用from_numpy()将NumPy数组转换成Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSKbLfhox3gQ",
        "outputId": "e16f5476-c733-4792-85f0-49106702e859"
      },
      "source": [
        "import numpy as np\r\n",
        "a = np.ones(5)\r\n",
        "b = torch.from_numpy(a)\r\n",
        "print(a,b)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHBUSXWyL-T",
        "outputId": "d91017a5-581d-475b-d904-c41f5928868a"
      },
      "source": [
        "a+=1\r\n",
        "print(a,b)\r\n",
        "b+=1\r\n",
        "print(a,b)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvjBKluy0CZ_"
      },
      "source": [
        "此外上面提到还有一个常用的方法就是直接用torch.tensor()将NumPy数组转换成Tensor，需要注意的是该方法总是会进行数据拷贝，返回的Tensor和原来的数据不再共享内存。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8-qSBNt0BSu",
        "outputId": "4b9df2c7-6415-462f-b660-cea02dbccc1b"
      },
      "source": [
        "c = torch.tensor(a)\r\n",
        "a += 1\r\n",
        "print(a,c)\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-NiET6k0L7g"
      },
      "source": [
        "## 5.Tensor on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5qPGbd60RSX"
      },
      "source": [
        "用方法to()可以将Tensor在CPU和GPU（需要硬件支持）之间相互移动。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_f65EzS0LHL",
        "outputId": "18e270b5-0fc8-4a01-bbca-fcdb8a132955"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec 22 14:25:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVanVPgc0fKU",
        "outputId": "b5417895-708b-4c30-f4c2-65419b7ef638"
      },
      "source": [
        "# 以下代码只有在PyTorch GPU版本上才会执行\r\n",
        "if torch.cuda.is_available():\r\n",
        "    device = torch.device(\"cuda\")          # GPU\r\n",
        "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\r\n",
        "    x = x.to(device)                       # 等价于 .to(\"cuda\")\r\n",
        "    z = x + y\r\n",
        "    print(z)\r\n",
        "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型\r\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 3], device='cuda:0')\n",
            "tensor([2., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}